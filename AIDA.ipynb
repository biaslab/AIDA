{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "another-industry",
   "metadata": {},
   "source": [
    "# Active Inference Design Agent (demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "understanding-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "using Rocket\n",
    "using ReactiveMP\n",
    "using GraphPPL\n",
    "using Distributions\n",
    "using LinearAlgebra\n",
    "import ProgressMeter\n",
    "using WAV\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fluid-annex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_coupled_learning (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include auxilary functions for data processing\n",
    "include(\"helpers/aida_segmentation.jl\")\n",
    "# include SNR quality metric\n",
    "include(\"helpers/aida_snr.jl\")\n",
    "# include SNR quality metric\n",
    "include(\"helpers/aida_ar.jl\")\n",
    "# include models and corresponding inference algos\n",
    "include(\"models_inferences.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fourth-grove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-partner",
   "metadata": {},
   "source": [
    "In this demo we will work with two different contexts (environemtns): babble and train noises. \n",
    "\n",
    "You can think of a user who keeps wandering around a train station: sometimes train arrives and he/she hears the train noises. When there is no train arriving to the platform, the user hears the babble from people waiting for the train.\n",
    "When someone starts talking to the user he would (maybe) prefer to damp the environmental noise and focus only on the speaker.\n",
    "\n",
    "Another possible scenario you can think of is the user who steps out of the train and goes to the bar, where people produce babble noise :D "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-chess",
   "metadata": {},
   "source": [
    "## Let's obtain priors for the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-forty",
   "metadata": {},
   "source": [
    "To make our model identifiabile, we would like to obtain priors for the environmental noises. To do this, we use Voice-Activity-Detection (VAD) to find the silent segments (with no speech). When those frames are identified, we fit them to AR model of order 2 to learn the parameters of AR.\n",
    "\n",
    "Surely, you can obtain the priors based on different logic. (to discuss (1) it doesn't have to be AR, (2) it doesn't have to be VAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "promising-warrant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load sound from .wav\n",
    "babble, fs = wavread(\"sound/AIDA/training/sp01_babble_sn0.wav\")\n",
    "# split babble into overlapping segments (default 0.01s=10ms, 0.0025=2.5ms)\n",
    "bbl_seg = get_frames(babble, fs)\n",
    "# compute number of segments\n",
    "bbl_totseg = size(bbl_seg, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ruled-column",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, fs = wavread(\"sound/AIDA/training/sp11_train_sn0.wav\")\n",
    "tr_seg = get_frames(train, fs)\n",
    "tr_totseg = size(tr_seg, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "monetary-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priors for contexts were obtained through running VAD-AR block\n",
    "# prior for train noise\n",
    "trmη = [0.4132104755921993 -0.16961911841949667]\n",
    "trvη = [0.00972993440498344 -0.0027103005529199036; -0.0027103005529199036 0.004281987640515784]\n",
    "# trτ  = (41.0, 0.03644943410647206)\n",
    "trτ  = (41.0, 0.05)\n",
    "\n",
    "# prior for babble noise\n",
    "bblmη = [1.1192255902602752 -0.43086292293101314]\n",
    "bblvη = [0.007837790430663492 -0.005039080815241558; -0.005039080815241558 0.00596413119195013]\n",
    "# bblτ  = (41.0, 0.0029780512310493387);\n",
    "bblτ  = (41.0, 0.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-occasions",
   "metadata": {},
   "source": [
    "### VAD block\n",
    "You can skip this entire block if you used priors from the above cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "driving-cowboy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lar_inference_ex (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"models/everything.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "falling-division",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ar_ssm (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import WAV\n",
    "include(\"helpers/aida_segmentation.jl\")\n",
    "include(\"helpers/aida_ar.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "close-jacksonville",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the auido signal from where you intend to extract the parameters\n",
    "context_seg = bbl_seg\n",
    "totseg = bbl_totseg\n",
    "# context_seg = tr_seg\n",
    "# totseg = tr_totseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "skilled-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_order = 10\n",
    "vmp_iter = 50\n",
    "fe_ar = zeros(totseg, vmp_iter)\n",
    "fe_gaussian = zeros(totseg, vmp_iter);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "southwest-envelope",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:08:47\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "ProgressMeter.@showprogress for segnum in 1:totseg\n",
    "    inputs, outputs = ar_ssm(context_seg[segnum, :], ar_order)\n",
    "    γ, τ, θ, x, fe = lar_inference_ex(outputs, ar_order, vmp_iter)\n",
    "    mθ, vθ = mean(θ), cov(θ)\n",
    "    mγ = mean(γ)\n",
    "    fe_ar[segnum, :] = fe\n",
    "    \n",
    "    x, γ, fe = inference_gaussian(outputs, vmp_iter, 1e4)\n",
    "    mx, vx = mean(x), cov(x)\n",
    "    mγ = mean(γ)\n",
    "    fe_gaussian[segnum, :] = fe\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cooked-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect silent frames based on model comparison\n",
    "vad = [x[end] < y[end] for (x, y) in zip(eachrow(fe_ar), eachrow(fe_gaussian))];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "pharmaceutical-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsegs = findall(isequal(1), vad)\n",
    "nsegs = findall(isequal(0), vad);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "empty-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.938993996124832"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv(var(sum([context_seg[nseg, :] for nseg in nsegs])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "monthly-mention",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:06\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "cmx, cvx, cmη, cvη, cτ = lar_batch_learning(hcat([context_seg[nseg, :] for nseg in nsegs]...)', 2, 10, 1e-12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "broadband-librarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1192255902602752 -0.43086292293101314], [0.007837790430663492 -0.005039080815241558; -0.005039080815241558 0.00596413119195013], , (41.0, 0.0029780512310493387)\n"
     ]
    }
   ],
   "source": [
    "println(\"$(mean(cmη, dims=1)), $(mean(cvη, dims=1)[1, :, :]), , $((cτ[end][1], cτ[end][2]))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priors for contexts were obtained through running VAD block\n",
    "trmη = mean(cmη, dims=1)\n",
    "trvη = mean(cvη, dims=1)[1, :, :]\n",
    "trτ  = (cτ[end][1], cτ[end][2])\n",
    "\n",
    "# prior for babble noise\n",
    "bblmη = mean(cmη, dims=1)\n",
    "bblvη = mean(cvη, dims=1)[1, :, :]\n",
    "bblτ  = (cτ[end][1], cτ[end][2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-julian",
   "metadata": {},
   "source": [
    "## Source seperation\n",
    "When priors for the contexts are indentified, we can run noise reduction algorithm based on coupled AR: AR_speech + AR_envrionment = output. This algorithm seperates speech (**z**) and noise (**x**)\n",
    "\n",
    "We will split our dataset into training and test set. We use signals from training set to learn the mapping function between the gains proposed by agent and aprraisals provided by user. Bare in mind that this split is not necessary and in theory we can get along without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "demographic-gibraltar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prior_to_priors (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coupled AR model is deisgned to work with time-varying priors for both speech and environmental noise\n",
    "# prior_to_priors map \"static\" priors to the corresponding matrices with equal elements\n",
    "function prior_to_priors(mη, vη, τ, totseg)\n",
    "    ar_order = size(mη, 2)\n",
    "    rmη = zeros(totseg, ar_order)\n",
    "    rvη = zeros(totseg, ar_order, ar_order)\n",
    "    for segnum in 1:totseg\n",
    "        rmη[segnum, :], rvη[segnum, :, :] = reshape(mη, (ar_order,)), vη\n",
    "    end\n",
    "    priors_eta = rmη, rvη\n",
    "    priors_tau = [τ for _ in 1:totseg]\n",
    "    priors_eta[1], priors_eta[2], priors_tau\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "lonely-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "trmη_arr, trvη_arr, trτ_arr = prior_to_priors(trmη, trvη, trτ, tr_totseg)\n",
    "bblmη_arr, bblvη_arr, bblτ_arr = prior_to_priors(bblmη, bblvη, bblτ, bbl_totseg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "large-humanitarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HA_algorithm (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function HA_algorithm(segments, priors_η, priors_τ, ar_1_order, ar_2_order, vmp_its)\n",
    "    \"\"\"Source seperation based on coupled AR model. Inference is performed in batch manner\n",
    "\n",
    "       segments: segmented audio signal\n",
    "       priors_η:   matrix of means and covariances of AR coefficients (see output formal of prior_to_priors\n",
    "       priors_τ:   array of tupes contatining the prior of environmental noise precision\n",
    "       ar_1_order: order of speech signal\n",
    "       ar_2_order: order of environmental noise signal\n",
    "       vmp_its:    number of variational iterations\n",
    "    \"\"\"\n",
    "    n_sources = 2\n",
    "    totseg = size(segments, 1)\n",
    "    l      = size(segments, 2) # dimensionality of the buffer\n",
    "    \n",
    "    rmx = zeros(totseg, l)\n",
    "    rvx = zeros(totseg, l)\n",
    "    rmθ = zeros(totseg, ar_1_order)\n",
    "    rvθ = zeros(totseg, ar_1_order, ar_1_order)\n",
    "    rγ = fill(tuple(.0, .0), totseg)\n",
    "    \n",
    "    rmz = zeros(totseg, l)\n",
    "    rvz = zeros(totseg, l)\n",
    "    rmη = zeros(totseg, ar_2_order)\n",
    "    rvη = zeros(totseg, ar_2_order, ar_2_order)\n",
    "    rτ = fill(tuple(.0, .0), totseg)\n",
    "    \n",
    "    fe  = zeros(totseg, vmp_its)\n",
    "    \n",
    "    rmo = zeros(totseg, l)\n",
    "    \n",
    "    # agent proposes gains according to its beliefs\n",
    "    ProgressMeter.@showprogress for segnum in 1:totseg\n",
    "        prior_η                           = (priors_η[1][segnum, :], priors_η[2][segnum, :, :])\n",
    "        prior_τ                           = priors_τ[segnum]\n",
    "        γ, θ, zs, τ, η, xs, fe[segnum, :] = coupled_inference(segments[segnum, :], prior_η, prior_τ, ar_1_order, ar_2_order, vmp_its)\n",
    "        mz, vz                            = mean.(zs), cov.(zs)\n",
    "        mθ, vθ                            = mean(θ), cov(θ)\n",
    "        rmz[segnum, :], rvz[segnum, :]    = first.(mz), first.(vz)\n",
    "        rmθ[segnum, :], rvθ[segnum, :, :] = mθ, vθ\n",
    "        rγ[segnum]                        = shape(γ), rate(γ)\n",
    "        \n",
    "        mx, vx                            = mean.(xs), cov.(xs)\n",
    "        mη, vη                            = mean(η), cov(η)\n",
    "        rmx[segnum, :], rvx[segnum, :]    = first.(mx), first.(vx)\n",
    "        rmη[segnum, :], rvη[segnum, :, :] = mη, vη\n",
    "        rτ[segnum]                        = shape(τ), rate(τ)\n",
    "        \n",
    "        # HA part\n",
    "        speech = rmz[segnum, :]\n",
    "        noise  = rmx[segnum, :]\n",
    "        rmo[segnum, :] = speech .+ noise\n",
    "    end\n",
    "    rmz, rvz, rmθ, rvθ, rγ, rmx, rvx, rmη, rvη, rτ, fe, rmo\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-regulation",
   "metadata": {},
   "source": [
    "#### Obtain the outputs from HA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "upper-latin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_sounds_fn (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return list of files from dir_name\n",
    "function get_sounds_fn(dir_name)\n",
    "    file_names = []\n",
    "    for (root, dirs, files) in walkdir(dir_name)\n",
    "        for file in files\n",
    "            push!(file_names, joinpath(root, file)) # path to files\n",
    "        end\n",
    "    end\n",
    "    file_names\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "metric-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = get_sounds_fn(\"sound/AIDA/training/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "compressed-latter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp08_babble_sn0.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "380×80 Matrix{Float64}:\n",
       "  0.0542314   0.0467544    0.00265511  …  -0.126011    -0.206244\n",
       "  0.033723    0.0573443    0.0773339      -0.0227058   -0.0657979\n",
       "  0.140538    0.106693     0.0360118       0.146092     0.0616169\n",
       "  0.0662252  -0.018128    -0.032075       -0.0811182    0.0431227\n",
       "  0.0480972   0.0445875    0.0498367      -0.0253609   -0.0185553\n",
       " -0.0292673  -0.0645466   -0.103793    …   0.14066      0.123875\n",
       " -0.0381481  -0.0107425    0.0104678       0.0936613    0.0746178\n",
       " -0.028077   -0.0843837   -0.0903348      -0.036256    -0.0307016\n",
       "  0.0492569   0.0639973    0.0399182       0.050264    -0.0648824\n",
       "  0.0670797   0.00317392   0.00521867      0.044496     0.0498978\n",
       " -0.101077   -0.0573138   -0.014069    …  -0.0697348   -0.0841395\n",
       "  0.0554827   0.0452589   -0.0309763       0.156255     0.0937223\n",
       " -0.0675069   0.0357677    0.0458998      -0.156713    -0.0555437\n",
       "  ⋮                                    ⋱               \n",
       "  0.0116581  -0.00210578  -0.0115665      -0.0350963   -0.0211493\n",
       " -0.0178533  -0.0216987   -0.0550859      -0.0550249   -0.0961638\n",
       "  0.0670492   0.0895108    0.0596026   …   0.0244758    0.0264901\n",
       " -0.0633869  -0.0693991   -0.0431227       0.032197     0.0103153\n",
       "  0.0513932   0.0548112    0.0653096      -0.00201422  -0.0256661\n",
       "  0.009064   -0.00671407  -0.00466933      0.0665609    0.028901\n",
       " -0.0514847   0.00173956   0.0195929      -0.0431532   -0.0391552\n",
       "  0.0169378  -0.00396741  -0.0189825   …   0.0251473   -0.0334788\n",
       " -0.0783105  -0.120151    -0.0912198       0.0107425   -0.0112003\n",
       " -0.0747703  -0.0825526   -0.0419324       0.0646992    0.10184\n",
       "  0.0134587   0.0128178    0.0318918       0.0203558    0.0274667\n",
       " -0.0343638  -0.0481277   -0.0563677       0.0          0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for how the data is organized\n",
    "training_file = training_files[8]\n",
    "println(training_file)\n",
    "speech, fs = WAV.wavread(training_file)\n",
    "speech_seg = get_frames(speech, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-exposure",
   "metadata": {},
   "source": [
    "At this stage we run our inference algorithm to seperate **z** and **x**. We write the output into *.jld* files.\n",
    "\n",
    "You don't need to run this snippet if you haven't changed the default parameters of HA_algorithm and priors (just see *sound/AIDA/separated_jld/training/*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "looking-kingdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp08_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:39\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp09_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:46\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp10_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:20\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp11_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:39\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp12_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:26\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp13_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:10\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp14_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:39\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp15_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:41\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp16_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:02:54\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp17_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp18_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:02:51\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp19_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:20\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp20_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:14\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "import JLD\n",
    "# r for recovered\n",
    "for training_file in training_files\n",
    "    println(training_file)\n",
    "    speech, fs = WAV.wavread(training_file)\n",
    "    speech_seg = get_frames(speech, fs)\n",
    "    # choose priors\n",
    "    priors_eta = occursin(\"babble\", training_file) ? (bblmη_arr, bblvη_arr) : (trmη_arr, trvη_arr)\n",
    "    priors_tau = occursin(\"babble\", training_file) ? bblτ_arr : trτ_arr\n",
    "    # make sure that 1D of priors and speech_seg are equal\n",
    "    if size(priors_eta, 1) != size(speech_seg, 1)\n",
    "        totseg = size(speech_seg, 1)\n",
    "        priors_eta_m, priors_eta_v, priors_tau = prior_to_priors(priors_eta[1][1, :]', priors_eta[2][1, :, :], priors_tau[1], totseg)\n",
    "        priors_eta = priors_eta_m, priors_eta_v\n",
    "    end\n",
    "    rmz, rvz, rmθ, rvθ, rγ, rmx, rvx, rmη, rvη, rτ, fe, rmo = HA_algorithm(speech_seg, priors_eta, priors_tau, 10, 2, 10);\n",
    "    \n",
    "    JLD.save(\"sound/AIDA/separated_jld/training/\"*training_file[findfirst(\"sp\", training_file)[1]:end][1:end-3]*\"jld\",\n",
    "         \"rmz\", rmz, \"rvz\", rvz, \"rmθ\", rmθ, \"rvθ\", rvθ, \"rγ\", rγ, \n",
    "         \"rmx\", rmx, \"rvx\", rvx, \"rmη\", rmη, \"rvη\", rvη, \"rτ\", rτ,\n",
    "         \"fe\", fe, \"rmo\", rmo, \"filename\", training_file,\n",
    "         \"audio\", speech)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-lyric",
   "metadata": {},
   "source": [
    "### Preference learning stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-accuracy",
   "metadata": {},
   "source": [
    "#### Generate outputs of HA from JLD files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "subsequent-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain saved jld files containing inference result\n",
    "training_jlds = get_sounds_fn(\"sound/AIDA/separated_jld/training/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "photographic-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize gains that agent randomly assigns to the outputs of HA\n",
    "agent_gains = [[2.0, 1.0], [1.0, 0.0], [0.5, 0.5], [0.9, 0.3], [2.5, 1.0]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this snippet generates new ha outputs\n",
    "for training_jld in training_jlds\n",
    "    # read file\n",
    "    d = JLD.load(training_jld)\n",
    "    filename = d[\"filename\"]\n",
    "    # extract speech\n",
    "    rmz, rmx = d[\"rmz\"], d[\"rmx\"]\n",
    "    # extract noise\n",
    "    rz, rx = get_signal(rmz, fs), get_signal(rmx, fs)\n",
    "    # pick weights \n",
    "    whgs = rand(agent_gains) # can be changed to a smarter function\n",
    "    # create output\n",
    "    ha_out = whgs[1] .* rz + whgs[2] .* rx\n",
    "    # write wav file\n",
    "    WAV.wavwrite(ha_out, fs, \"sound/AIDA/preference_learning/ha_out_$(whgs[1])_$(whgs[2])_\"*filename[findfirst(\"sp\", filename)[1]:end])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-pierce",
   "metadata": {},
   "source": [
    "#### Create pairs (gains, context) <-> appraisals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "attractive-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recorded gains and appraisals \n",
    "# If you want to generate new pairs, please procceed with listening\n",
    "gains = [[0.5, 0.5], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [2.0, 1.0], [2.0, 1.0], [2.5, 1.0], [2.5, 1.0], [2.5, 1.0]]\n",
    "appraisals = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]\n",
    "contexts = [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hazardous-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "prl_files = get_sounds_fn(\"sound/AIDA/preference_learning/\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-submission",
   "metadata": {},
   "source": [
    "#### Listening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-ghana",
   "metadata": {},
   "source": [
    "User gets to listen new audio samples with proposed gains. After each listening he/she evaluates the performance of HA output by binary feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet creates interactive loop where user can like/dislike hearing aid output\n",
    "nnum = 8 # prefix for gains\n",
    "appraisals = []\n",
    "gains = []\n",
    "contexts = []\n",
    "for prl_file in prl_files\n",
    "    \n",
    "    if !occursin(\"wav\", prl_file)\n",
    "        continue\n",
    "    end\n",
    "    WAV.wavplay(prl_file)\n",
    "    println(\"How's HA output 1, 0 ?\")\n",
    "    appraisal = readline()\n",
    "    push!(appraisals, parse(Float64, appraisal))\n",
    "    \n",
    "    # extract gains routine\n",
    "    pref_id = findfirst(\"out_\", prl_file)[end]\n",
    "    gains_str = prl_file[pref_id+1:pref_id+nnum-1]\n",
    "    push!(gains, parse.(Float64, split(gains_str, \"_\")))\n",
    "    \n",
    "    # extract context routine\n",
    "    push!(contexts, occursin(\"babble\", prl_file) ? 1.0 : 0.0)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "rural-richards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5, 0.5], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [2.0, 1.0], [2.0, 1.0], [2.5, 1.0], [2.5, 1.0], [2.5, 1.0]]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "println(gains)\n",
    "println(appraisals)\n",
    "println(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "educational-adams",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flow_optimize (generic function with 1 method)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizing flows agent\n",
    "include(\"agent/agent_Bart/flow_agent.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "breathing-infrastructure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 1.0\n",
       " 1.0\n",
       " 0.0\n",
       " 1.0\n",
       " ⋮\n",
       " 0.0\n",
       " 1.0\n",
       " 1.0\n",
       " 0.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 0.0\n",
       " 1.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# augmentation of the dataset with copies\n",
    "n_gains = vcat(hcat(gains...)', hcat(gains...)', hcat(gains...)')\n",
    "n_appraisals = vcat(appraisals, appraisals, appraisals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "empty-envelope",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60×2 Matrix{Float64}:\n",
       " 0.268831   0.475686\n",
       " 0.951661   0.27058\n",
       " 0.872548   0.363539\n",
       " 0.960532   0.22162\n",
       " 0.776812   0.178116\n",
       " 0.950262   0.224163\n",
       " 0.927391   0.189461\n",
       " 0.874978   0.381843\n",
       " 0.711653   0.502628\n",
       " 0.82581    0.401254\n",
       " 0.993345  -0.00183917\n",
       " 1.11326   -0.0818019\n",
       " 1.00006    0.13864\n",
       " ⋮         \n",
       " 0.842841   0.0475403\n",
       " 0.892865   0.064773\n",
       " 1.00509    0.0226811\n",
       " 0.880409  -0.0510568\n",
       " 0.970922   0.0823548\n",
       " 0.934788   0.0286015\n",
       " 0.991263   0.0565874\n",
       " 2.1106     1.02648\n",
       " 1.83433    1.09593\n",
       " 2.48196    0.942216\n",
       " 2.38583    0.887885\n",
       " 2.40317    0.943601"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# augmentation of the dataset with copies\n",
    "data_y = n_appraisals\n",
    "m_gains = n_gains .+ sqrt(1e-2)*randn(size(n_gains))\n",
    "data_x = m_gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "tropical-sierra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip780\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip780)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip781\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip780)\" d=\"\n",
       "M249.542 1423.18 L2352.76 1423.18 L2352.76 47.2441 L249.542 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip782\">\n",
       "    <rect x=\"249\" y=\"47\" width=\"2104\" height=\"1377\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  509.584,1423.18 509.584,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  943.288,1423.18 943.288,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1376.99,1423.18 1376.99,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1810.7,1423.18 1810.7,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2244.4,1423.18 2244.4,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip780)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  249.542,1423.18 2352.76,1423.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip780)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  509.584,1423.18 509.584,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip780)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  943.288,1423.18 943.288,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip780)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1376.99,1423.18 1376.99,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip780)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1810.7,1423.18 1810.7,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip780)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2244.4,1423.18 2244.4,1404.28 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip780)\" d=\"M487.466 1452.37 Q483.855 1452.37 482.027 1455.94 Q480.221 1459.48 480.221 1466.61 Q480.221 1473.71 482.027 1477.28 Q483.855 1480.82 487.466 1480.82 Q491.101 1480.82 492.906 1477.28 Q494.735 1473.71 494.735 1466.61 Q494.735 1459.48 492.906 1455.94 Q491.101 1452.37 487.466 1452.37 M487.466 1448.67 Q493.277 1448.67 496.332 1453.27 Q499.411 1457.86 499.411 1466.61 Q499.411 1475.33 496.332 1479.94 Q493.277 1484.52 487.466 1484.52 Q481.656 1484.52 478.578 1479.94 Q475.522 1475.33 475.522 1466.61 Q475.522 1457.86 478.578 1453.27 Q481.656 1448.67 487.466 1448.67 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M507.628 1477.97 L512.513 1477.97 L512.513 1483.85 L507.628 1483.85 L507.628 1477.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M522.744 1449.29 L541.1 1449.29 L541.1 1453.23 L527.026 1453.23 L527.026 1461.7 Q528.045 1461.35 529.063 1461.19 Q530.082 1461 531.1 1461 Q536.887 1461 540.267 1464.18 Q543.647 1467.35 543.647 1472.76 Q543.647 1478.34 540.174 1481.44 Q536.702 1484.52 530.383 1484.52 Q528.207 1484.52 525.938 1484.15 Q523.693 1483.78 521.286 1483.04 L521.286 1478.34 Q523.369 1479.48 525.591 1480.03 Q527.813 1480.59 530.29 1480.59 Q534.295 1480.59 536.633 1478.48 Q538.971 1476.38 538.971 1472.76 Q538.971 1469.15 536.633 1467.05 Q534.295 1464.94 530.29 1464.94 Q528.415 1464.94 526.54 1465.36 Q524.688 1465.77 522.744 1466.65 L522.744 1449.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M910.441 1479.92 L918.08 1479.92 L918.08 1453.55 L909.77 1455.22 L909.77 1450.96 L918.034 1449.29 L922.709 1449.29 L922.709 1479.92 L930.348 1479.92 L930.348 1483.85 L910.441 1483.85 L910.441 1479.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M939.793 1477.97 L944.677 1477.97 L944.677 1483.85 L939.793 1483.85 L939.793 1477.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M964.862 1452.37 Q961.251 1452.37 959.422 1455.94 Q957.617 1459.48 957.617 1466.61 Q957.617 1473.71 959.422 1477.28 Q961.251 1480.82 964.862 1480.82 Q968.496 1480.82 970.302 1477.28 Q972.131 1473.71 972.131 1466.61 Q972.131 1459.48 970.302 1455.94 Q968.496 1452.37 964.862 1452.37 M964.862 1448.67 Q970.672 1448.67 973.728 1453.27 Q976.806 1457.86 976.806 1466.61 Q976.806 1475.33 973.728 1479.94 Q970.672 1484.52 964.862 1484.52 Q959.052 1484.52 955.973 1479.94 Q952.918 1475.33 952.918 1466.61 Q952.918 1457.86 955.973 1453.27 Q959.052 1448.67 964.862 1448.67 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M1344.64 1479.92 L1352.28 1479.92 L1352.28 1453.55 L1343.97 1455.22 L1343.97 1450.96 L1352.24 1449.29 L1356.91 1449.29 L1356.91 1479.92 L1364.55 1479.92 L1364.55 1483.85 L1344.64 1483.85 L1344.64 1479.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M1373.99 1477.97 L1378.88 1477.97 L1378.88 1483.85 L1373.99 1483.85 L1373.99 1477.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M1389.11 1449.29 L1407.47 1449.29 L1407.47 1453.23 L1393.39 1453.23 L1393.39 1461.7 Q1394.41 1461.35 1395.43 1461.19 Q1396.45 1461 1397.47 1461 Q1403.25 1461 1406.63 1464.18 Q1410.01 1467.35 1410.01 1472.76 Q1410.01 1478.34 1406.54 1481.44 Q1403.07 1484.52 1396.75 1484.52 Q1394.57 1484.52 1392.3 1484.15 Q1390.06 1483.78 1387.65 1483.04 L1387.65 1478.34 Q1389.73 1479.48 1391.96 1480.03 Q1394.18 1480.59 1396.66 1480.59 Q1400.66 1480.59 1403 1478.48 Q1405.34 1476.38 1405.34 1472.76 Q1405.34 1469.15 1403 1467.05 Q1400.66 1464.94 1396.66 1464.94 Q1394.78 1464.94 1392.91 1465.36 Q1391.05 1465.77 1389.11 1466.65 L1389.11 1449.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M1781.93 1479.92 L1798.25 1479.92 L1798.25 1483.85 L1776.31 1483.85 L1776.31 1479.92 Q1778.97 1477.16 1783.55 1472.53 Q1788.16 1467.88 1789.34 1466.54 Q1791.59 1464.01 1792.47 1462.28 Q1793.37 1460.52 1793.37 1458.83 Q1793.37 1456.07 1791.42 1454.34 Q1789.5 1452.6 1786.4 1452.6 Q1784.2 1452.6 1781.75 1453.37 Q1779.32 1454.13 1776.54 1455.68 L1776.54 1450.96 Q1779.36 1449.82 1781.82 1449.25 Q1784.27 1448.67 1786.31 1448.67 Q1791.68 1448.67 1794.87 1451.35 Q1798.07 1454.04 1798.07 1458.53 Q1798.07 1460.66 1797.26 1462.58 Q1796.47 1464.48 1794.36 1467.07 Q1793.79 1467.74 1790.68 1470.96 Q1787.58 1474.15 1781.93 1479.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M1808.07 1477.97 L1812.95 1477.97 L1812.95 1483.85 L1808.07 1483.85 L1808.07 1477.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M1833.14 1452.37 Q1829.53 1452.37 1827.7 1455.94 Q1825.89 1459.48 1825.89 1466.61 Q1825.89 1473.71 1827.7 1477.28 Q1829.53 1480.82 1833.14 1480.82 Q1836.77 1480.82 1838.58 1477.28 Q1840.41 1473.71 1840.41 1466.61 Q1840.41 1459.48 1838.58 1455.94 Q1836.77 1452.37 1833.14 1452.37 M1833.14 1448.67 Q1838.95 1448.67 1842 1453.27 Q1845.08 1457.86 1845.08 1466.61 Q1845.08 1475.33 1842 1479.94 Q1838.95 1484.52 1833.14 1484.52 Q1827.33 1484.52 1824.25 1479.94 Q1821.19 1475.33 1821.19 1466.61 Q1821.19 1457.86 1824.25 1453.27 Q1827.33 1448.67 1833.14 1448.67 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M2216.14 1479.92 L2232.45 1479.92 L2232.45 1483.85 L2210.51 1483.85 L2210.51 1479.92 Q2213.17 1477.16 2217.76 1472.53 Q2222.36 1467.88 2223.54 1466.54 Q2225.79 1464.01 2226.67 1462.28 Q2227.57 1460.52 2227.57 1458.83 Q2227.57 1456.07 2225.63 1454.34 Q2223.7 1452.6 2220.6 1452.6 Q2218.4 1452.6 2215.95 1453.37 Q2213.52 1454.13 2210.74 1455.68 L2210.74 1450.96 Q2213.57 1449.82 2216.02 1449.25 Q2218.47 1448.67 2220.51 1448.67 Q2225.88 1448.67 2229.08 1451.35 Q2232.27 1454.04 2232.27 1458.53 Q2232.27 1460.66 2231.46 1462.58 Q2230.67 1464.48 2228.57 1467.07 Q2227.99 1467.74 2224.89 1470.96 Q2221.78 1474.15 2216.14 1479.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M2242.27 1477.97 L2247.15 1477.97 L2247.15 1483.85 L2242.27 1483.85 L2242.27 1477.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M2257.39 1449.29 L2275.74 1449.29 L2275.74 1453.23 L2261.67 1453.23 L2261.67 1461.7 Q2262.69 1461.35 2263.7 1461.19 Q2264.72 1461 2265.74 1461 Q2271.53 1461 2274.91 1464.18 Q2278.29 1467.35 2278.29 1472.76 Q2278.29 1478.34 2274.82 1481.44 Q2271.34 1484.52 2265.02 1484.52 Q2262.85 1484.52 2260.58 1484.15 Q2258.33 1483.78 2255.93 1483.04 L2255.93 1478.34 Q2258.01 1479.48 2260.23 1480.03 Q2262.45 1480.59 2264.93 1480.59 Q2268.94 1480.59 2271.27 1478.48 Q2273.61 1476.38 2273.61 1472.76 Q2273.61 1469.15 2271.27 1467.05 Q2268.94 1464.94 2264.93 1464.94 Q2263.06 1464.94 2261.18 1465.36 Q2259.33 1465.77 2257.39 1466.65 L2257.39 1449.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M1290.53 1549.81 Q1290.53 1543.44 1287.89 1539.94 Q1285.28 1536.44 1280.54 1536.44 Q1275.83 1536.44 1273.19 1539.94 Q1270.58 1543.44 1270.58 1549.81 Q1270.58 1556.14 1273.19 1559.64 Q1275.83 1563.14 1280.54 1563.14 Q1285.28 1563.14 1287.89 1559.64 Q1290.53 1556.14 1290.53 1549.81 M1296.39 1563.62 Q1296.39 1572.72 1292.35 1577.15 Q1288.31 1581.6 1279.97 1581.6 Q1276.88 1581.6 1274.14 1581.13 Q1271.41 1580.68 1268.83 1579.72 L1268.83 1574.03 Q1271.41 1575.43 1273.92 1576.1 Q1276.43 1576.76 1279.04 1576.76 Q1284.81 1576.76 1287.67 1573.74 Q1290.53 1570.75 1290.53 1564.67 L1290.53 1561.77 Q1288.72 1564.92 1285.89 1566.48 Q1283.05 1568.04 1279.11 1568.04 Q1272.55 1568.04 1268.54 1563.05 Q1264.53 1558.05 1264.53 1549.81 Q1264.53 1541.53 1268.54 1536.53 Q1272.55 1531.54 1279.11 1531.54 Q1283.05 1531.54 1285.89 1533.1 Q1288.72 1534.66 1290.53 1537.81 L1290.53 1532.4 L1296.39 1532.4 L1296.39 1563.62 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M1310.4 1562.63 L1320.9 1562.63 L1320.9 1526.38 L1309.47 1528.67 L1309.47 1522.82 L1320.83 1520.52 L1327.26 1520.52 L1327.26 1562.63 L1337.77 1562.63 L1337.77 1568.04 L1310.4 1568.04 L1310.4 1562.63 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  249.542,1286.7 2352.76,1286.7 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  249.542,1013.67 2352.76,1013.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  249.542,740.632 2352.76,740.632 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  249.542,467.598 2352.76,467.598 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  249.542,194.565 2352.76,194.565 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip780)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  249.542,1423.18 249.542,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip780)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  249.542,1286.7 268.44,1286.7 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip780)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  249.542,1013.67 268.44,1013.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip780)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  249.542,740.632 268.44,740.632 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip780)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  249.542,467.598 268.44,467.598 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip780)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  249.542,194.565 268.44,194.565 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip780)\" d=\"M126.205 1272.5 Q122.593 1272.5 120.765 1276.06 Q118.959 1279.6 118.959 1286.73 Q118.959 1293.84 120.765 1297.4 Q122.593 1300.95 126.205 1300.95 Q129.839 1300.95 131.644 1297.4 Q133.473 1293.84 133.473 1286.73 Q133.473 1279.6 131.644 1276.06 Q129.839 1272.5 126.205 1272.5 M126.205 1268.79 Q132.015 1268.79 135.07 1273.4 Q138.149 1277.98 138.149 1286.73 Q138.149 1295.46 135.07 1300.07 Q132.015 1304.65 126.205 1304.65 Q120.394 1304.65 117.316 1300.07 Q114.26 1295.46 114.26 1286.73 Q114.26 1277.98 117.316 1273.4 Q120.394 1268.79 126.205 1268.79 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M146.366 1298.1 L151.251 1298.1 L151.251 1303.98 L146.366 1303.98 L146.366 1298.1 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M171.436 1272.5 Q167.825 1272.5 165.996 1276.06 Q164.19 1279.6 164.19 1286.73 Q164.19 1293.84 165.996 1297.4 Q167.825 1300.95 171.436 1300.95 Q175.07 1300.95 176.876 1297.4 Q178.704 1293.84 178.704 1286.73 Q178.704 1279.6 176.876 1276.06 Q175.07 1272.5 171.436 1272.5 M171.436 1268.79 Q177.246 1268.79 180.301 1273.4 Q183.38 1277.98 183.38 1286.73 Q183.38 1295.46 180.301 1300.07 Q177.246 1304.65 171.436 1304.65 Q165.626 1304.65 162.547 1300.07 Q159.491 1295.46 159.491 1286.73 Q159.491 1277.98 162.547 1273.4 Q165.626 1268.79 171.436 1268.79 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M201.598 1272.5 Q197.987 1272.5 196.158 1276.06 Q194.352 1279.6 194.352 1286.73 Q194.352 1293.84 196.158 1297.4 Q197.987 1300.95 201.598 1300.95 Q205.232 1300.95 207.037 1297.4 Q208.866 1293.84 208.866 1286.73 Q208.866 1279.6 207.037 1276.06 Q205.232 1272.5 201.598 1272.5 M201.598 1268.79 Q207.408 1268.79 210.463 1273.4 Q213.542 1277.98 213.542 1286.73 Q213.542 1295.46 210.463 1300.07 Q207.408 1304.65 201.598 1304.65 Q195.787 1304.65 192.709 1300.07 Q189.653 1295.46 189.653 1286.73 Q189.653 1277.98 192.709 1273.4 Q195.787 1268.79 201.598 1268.79 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M127.2 999.464 Q123.589 999.464 121.76 1003.03 Q119.955 1006.57 119.955 1013.7 Q119.955 1020.81 121.76 1024.37 Q123.589 1027.91 127.2 1027.91 Q130.834 1027.91 132.64 1024.37 Q134.468 1020.81 134.468 1013.7 Q134.468 1006.57 132.64 1003.03 Q130.834 999.464 127.2 999.464 M127.2 995.76 Q133.01 995.76 136.066 1000.37 Q139.144 1004.95 139.144 1013.7 Q139.144 1022.43 136.066 1027.03 Q133.01 1031.62 127.2 1031.62 Q121.39 1031.62 118.311 1027.03 Q115.256 1022.43 115.256 1013.7 Q115.256 1004.95 118.311 1000.37 Q121.39 995.76 127.2 995.76 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M147.362 1025.07 L152.246 1025.07 L152.246 1030.95 L147.362 1030.95 L147.362 1025.07 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M166.459 1027.01 L182.778 1027.01 L182.778 1030.95 L160.834 1030.95 L160.834 1027.01 Q163.496 1024.26 168.079 1019.63 Q172.686 1014.97 173.866 1013.63 Q176.112 1011.11 176.991 1009.37 Q177.894 1007.61 177.894 1005.92 Q177.894 1003.17 175.95 1001.43 Q174.028 999.695 170.927 999.695 Q168.727 999.695 166.274 1000.46 Q163.843 1001.22 161.065 1002.77 L161.065 998.052 Q163.89 996.917 166.343 996.339 Q168.797 995.76 170.834 995.76 Q176.204 995.76 179.399 998.445 Q182.593 1001.13 182.593 1005.62 Q182.593 1007.75 181.783 1009.67 Q180.996 1011.57 178.889 1014.16 Q178.311 1014.83 175.209 1018.05 Q172.107 1021.25 166.459 1027.01 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M192.639 996.385 L210.996 996.385 L210.996 1000.32 L196.922 1000.32 L196.922 1008.79 Q197.94 1008.45 198.959 1008.28 Q199.977 1008.1 200.996 1008.1 Q206.783 1008.1 210.162 1011.27 Q213.542 1014.44 213.542 1019.86 Q213.542 1025.44 210.07 1028.54 Q206.598 1031.62 200.278 1031.62 Q198.102 1031.62 195.834 1031.25 Q193.588 1030.88 191.181 1030.13 L191.181 1025.44 Q193.264 1026.57 195.487 1027.13 Q197.709 1027.68 200.186 1027.68 Q204.19 1027.68 206.528 1025.57 Q208.866 1023.47 208.866 1019.86 Q208.866 1016.25 206.528 1014.14 Q204.19 1012.03 200.186 1012.03 Q198.311 1012.03 196.436 1012.45 Q194.584 1012.87 192.639 1013.75 L192.639 996.385 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M126.205 726.43 Q122.593 726.43 120.765 729.995 Q118.959 733.537 118.959 740.666 Q118.959 747.773 120.765 751.338 Q122.593 754.879 126.205 754.879 Q129.839 754.879 131.644 751.338 Q133.473 747.773 133.473 740.666 Q133.473 733.537 131.644 729.995 Q129.839 726.43 126.205 726.43 M126.205 722.727 Q132.015 722.727 135.07 727.333 Q138.149 731.916 138.149 740.666 Q138.149 749.393 135.07 754 Q132.015 758.583 126.205 758.583 Q120.394 758.583 117.316 754 Q114.26 749.393 114.26 740.666 Q114.26 731.916 117.316 727.333 Q120.394 722.727 126.205 722.727 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M146.366 752.032 L151.251 752.032 L151.251 757.912 L146.366 757.912 L146.366 752.032 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M161.482 723.352 L179.839 723.352 L179.839 727.287 L165.765 727.287 L165.765 735.759 Q166.783 735.412 167.802 735.25 Q168.82 735.065 169.839 735.065 Q175.626 735.065 179.005 738.236 Q182.385 741.407 182.385 746.824 Q182.385 752.402 178.913 755.504 Q175.44 758.583 169.121 758.583 Q166.945 758.583 164.677 758.213 Q162.431 757.842 160.024 757.101 L160.024 752.402 Q162.107 753.537 164.329 754.092 Q166.552 754.648 169.028 754.648 Q173.033 754.648 175.371 752.541 Q177.709 750.435 177.709 746.824 Q177.709 743.213 175.371 741.106 Q173.033 739 169.028 739 Q167.153 739 165.278 739.416 Q163.427 739.833 161.482 740.713 L161.482 723.352 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M201.598 726.43 Q197.987 726.43 196.158 729.995 Q194.352 733.537 194.352 740.666 Q194.352 747.773 196.158 751.338 Q197.987 754.879 201.598 754.879 Q205.232 754.879 207.037 751.338 Q208.866 747.773 208.866 740.666 Q208.866 733.537 207.037 729.995 Q205.232 726.43 201.598 726.43 M201.598 722.727 Q207.408 722.727 210.463 727.333 Q213.542 731.916 213.542 740.666 Q213.542 749.393 210.463 754 Q207.408 758.583 201.598 758.583 Q195.787 758.583 192.709 754 Q189.653 749.393 189.653 740.666 Q189.653 731.916 192.709 727.333 Q195.787 722.727 201.598 722.727 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M127.2 453.397 Q123.589 453.397 121.76 456.962 Q119.955 460.503 119.955 467.633 Q119.955 474.739 121.76 478.304 Q123.589 481.846 127.2 481.846 Q130.834 481.846 132.64 478.304 Q134.468 474.739 134.468 467.633 Q134.468 460.503 132.64 456.962 Q130.834 453.397 127.2 453.397 M127.2 449.693 Q133.01 449.693 136.066 454.3 Q139.144 458.883 139.144 467.633 Q139.144 476.36 136.066 480.966 Q133.01 485.55 127.2 485.55 Q121.39 485.55 118.311 480.966 Q115.256 476.36 115.256 467.633 Q115.256 458.883 118.311 454.3 Q121.39 449.693 127.2 449.693 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M147.362 478.999 L152.246 478.999 L152.246 484.878 L147.362 484.878 L147.362 478.999 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M161.251 450.318 L183.473 450.318 L183.473 452.309 L170.927 484.878 L166.042 484.878 L177.848 454.253 L161.251 454.253 L161.251 450.318 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M192.639 450.318 L210.996 450.318 L210.996 454.253 L196.922 454.253 L196.922 462.726 Q197.94 462.378 198.959 462.216 Q199.977 462.031 200.996 462.031 Q206.783 462.031 210.162 465.202 Q213.542 468.374 213.542 473.79 Q213.542 479.369 210.07 482.471 Q206.598 485.55 200.278 485.55 Q198.102 485.55 195.834 485.179 Q193.588 484.809 191.181 484.068 L191.181 479.369 Q193.264 480.503 195.487 481.059 Q197.709 481.614 200.186 481.614 Q204.19 481.614 206.528 479.508 Q208.866 477.401 208.866 473.79 Q208.866 470.179 206.528 468.073 Q204.19 465.966 200.186 465.966 Q198.311 465.966 196.436 466.383 Q194.584 466.8 192.639 467.679 L192.639 450.318 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M117.015 207.91 L124.654 207.91 L124.654 181.544 L116.343 183.211 L116.343 178.951 L124.607 177.285 L129.283 177.285 L129.283 207.91 L136.922 207.91 L136.922 211.845 L117.015 211.845 L117.015 207.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M146.366 205.965 L151.251 205.965 L151.251 211.845 L146.366 211.845 L146.366 205.965 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M171.436 180.363 Q167.825 180.363 165.996 183.928 Q164.19 187.47 164.19 194.6 Q164.19 201.706 165.996 205.271 Q167.825 208.812 171.436 208.812 Q175.07 208.812 176.876 205.271 Q178.704 201.706 178.704 194.6 Q178.704 187.47 176.876 183.928 Q175.07 180.363 171.436 180.363 M171.436 176.66 Q177.246 176.66 180.301 181.266 Q183.38 185.85 183.38 194.6 Q183.38 203.326 180.301 207.933 Q177.246 212.516 171.436 212.516 Q165.626 212.516 162.547 207.933 Q159.491 203.326 159.491 194.6 Q159.491 185.85 162.547 181.266 Q165.626 176.66 171.436 176.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M201.598 180.363 Q197.987 180.363 196.158 183.928 Q194.352 187.47 194.352 194.6 Q194.352 201.706 196.158 205.271 Q197.987 208.812 201.598 208.812 Q205.232 208.812 207.037 205.271 Q208.866 201.706 208.866 194.6 Q208.866 187.47 207.037 183.928 Q205.232 180.363 201.598 180.363 M201.598 176.66 Q207.408 176.66 210.463 181.266 Q213.542 185.85 213.542 194.6 Q213.542 203.326 210.463 207.933 Q207.408 212.516 201.598 212.516 Q195.787 212.516 192.709 207.933 Q189.653 203.326 189.653 194.6 Q189.653 185.85 192.709 181.266 Q195.787 176.66 201.598 176.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M45.7664 745.572 Q39.4007 745.572 35.8996 748.214 Q32.3984 750.824 32.3984 755.566 Q32.3984 760.277 35.8996 762.919 Q39.4007 765.529 45.7664 765.529 Q52.1003 765.529 55.6014 762.919 Q59.1026 760.277 59.1026 755.566 Q59.1026 750.824 55.6014 748.214 Q52.1003 745.572 45.7664 745.572 M59.58 739.716 Q68.683 739.716 73.1071 743.758 Q77.5631 747.8 77.5631 756.139 Q77.5631 759.227 77.0857 761.964 Q76.6401 764.701 75.6852 767.279 L69.9879 767.279 Q71.3884 764.701 72.0568 762.187 Q72.7252 759.672 72.7252 757.062 Q72.7252 751.301 69.7015 748.437 Q66.7096 745.572 60.6303 745.572 L57.7339 745.572 Q60.885 747.386 62.4446 750.219 Q64.0042 753.052 64.0042 756.999 Q64.0042 763.555 59.0071 767.566 Q54.01 771.576 45.7664 771.576 Q37.491 771.576 32.4939 767.566 Q27.4968 763.555 27.4968 756.999 Q27.4968 753.052 29.0564 750.219 Q30.616 747.386 33.7671 745.572 L28.3562 745.572 L28.3562 739.716 L59.58 739.716 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip780)\" d=\"M58.5933 721.287 L58.5933 698.848 L64.0042 698.848 L64.0042 729.021 L58.5933 729.021 Q54.8057 725.361 48.44 719.059 Q42.0425 712.725 40.1964 711.102 Q36.7271 708.014 34.34 706.805 Q31.921 705.564 29.5975 705.564 Q25.8099 705.564 23.4228 708.237 Q21.0356 710.879 21.0356 715.144 Q21.0356 718.168 22.086 721.542 Q23.1363 724.884 25.2688 728.703 L18.7758 728.703 Q17.2162 724.82 16.4205 721.446 Q15.6248 718.072 15.6248 715.271 Q15.6248 707.887 19.3169 703.495 Q23.009 699.102 29.1837 699.102 Q32.112 699.102 34.7537 700.216 Q37.3637 701.299 40.9285 704.195 Q41.8515 704.991 46.2757 709.256 Q50.668 713.521 58.5933 721.287 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><circle clip-path=\"url(#clip782)\" cx=\"309.067\" cy=\"767.186\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"901.359\" cy=\"991.189\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"832.736\" cy=\"889.665\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"909.053\" cy=\"1044.66\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"749.693\" cy=\"1092.17\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"900.145\" cy=\"1041.88\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"880.307\" cy=\"1079.78\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"834.843\" cy=\"869.675\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"693.174\" cy=\"737.762\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"792.195\" cy=\"848.475\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"937.516\" cy=\"1288.71\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"1041.53\" cy=\"1376.04\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"943.339\" cy=\"1135.28\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"833.669\" cy=\"1262.88\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"942.787\" cy=\"1255.22\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"1811.8\" cy=\"271.492\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"1687.76\" cy=\"346.336\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"2172.06\" cy=\"261.589\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"2277.31\" cy=\"283.585\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"2223.72\" cy=\"215.785\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"469.441\" cy=\"862.738\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"972.643\" cy=\"848.593\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"899.825\" cy=\"831.521\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"873.97\" cy=\"891.325\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"829.22\" cy=\"982.54\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"897.741\" cy=\"939.313\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"754.194\" cy=\"943.658\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"791.737\" cy=\"945.722\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"924.06\" cy=\"998.015\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"915.55\" cy=\"1069.09\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"892.82\" cy=\"1287.82\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"972.927\" cy=\"1384.24\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"1092.47\" cy=\"1065.01\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"818.418\" cy=\"1131.42\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"1013.59\" cy=\"1165.8\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"1776.11\" cy=\"86.1857\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"1675.76\" cy=\"245.873\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"2224.92\" cy=\"282.545\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"2240.53\" cy=\"324.851\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"2293.23\" cy=\"224.259\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"526.482\" cy=\"655.489\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"778.083\" cy=\"982.823\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"986.118\" cy=\"726.86\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"706.281\" cy=\"945.741\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"861.582\" cy=\"964.892\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"928.609\" cy=\"1001\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"957.771\" cy=\"970.069\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"929.894\" cy=\"1155.26\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"806.967\" cy=\"1234.78\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"850.359\" cy=\"1215.96\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"947.706\" cy=\"1261.93\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"839.554\" cy=\"1342.46\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"918.065\" cy=\"1196.76\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"886.723\" cy=\"1255.46\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"935.709\" cy=\"1224.9\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"1906.63\" cy=\"165.643\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"1666.99\" cy=\"89.8015\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"2228.75\" cy=\"257.673\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"2145.37\" cy=\"317.009\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"2160.4\" cy=\"256.16\" r=\"14\" fill=\"#6b9e32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatter(data_x[:,1], data_x[:,2], color=Int64.(data_y), legend=false)\n",
    "xlabel!(\"g1\")\n",
    "ylabel!(\"g2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "iraqi-secretary",
   "metadata": {},
   "outputs": [],
   "source": [
    "function f(params)\n",
    "    fe = inference_flow_classifier(data_y, [data_x[k,:] for k=1:size(data_x,1)], params)\n",
    "    return fe\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "impressive-dover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     Function value   Gradient norm \n",
      "     0              NaN              NaN\n",
      " * time: 0.00013518333435058594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     NaN\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     L-BFGS\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 0.00e+00 ≤ 0.0e+00\n",
       "    |x - x'|/|x'|          = 0.00e+00 ≤ 0.0e+00\n",
       "    |f(x) - f(x')|         = NaN ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = NaN ≰ 0.0e+00\n",
       "    |g(x)|                 = NaN ≰ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    0\n",
       "    f(x) calls:    1\n",
       "    ∇f(x) calls:   1\n"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = optimize(f, randn(12), LBFGS(), Optim.Options(store_trace = true, show_trace = true), autodiff=:forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "authentic-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling based agent. \n",
    "include(\"agent/agent_sampling.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sublime-costa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learning (generic function with 2 methods)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns paramaters of a neural netwrok that provides the highest log posterior.\n",
    "function learning(gains, contexts, appraisals, N=1000; g_jitter=1e-4)\n",
    "    # adding jitter to gains might be useful when dealing with small number of observations\n",
    "    gains = [g .+ sqrt(g_jitter)*randn(length(g)) for g in gains]\n",
    "    inputs = [vcat(g, c) for (g, c) in zip(gains, contexts)]\n",
    "    ch = Turing.sample(prefernce_learning(hcat(inputs...), appraisals, 1.0), Turing.HMC(0.05, 10), N);\n",
    "    # Extract all weight and bias parameters.\n",
    "    theta = Turing.MCMCChains.group(ch, :nn_params).value;\n",
    "    # Find the index that provided the highest log posterior in the chain.\n",
    "    _, i = findmax(ch[:lp])\n",
    "    i = i.I[1]\n",
    "    θ = Float64.(theta[i, :])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "assumed-access",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "nn_params = learning(gains, contexts, appraisals);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "choice-iceland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Alternative (in case you don't want to use learning function)\n",
    "gains₊ = [g .+ sqrt(1e-4)*randn(length(g)) for g in gains]\n",
    "inputs = [vcat(g, c) for (g, c) in zip(gains, contexts)]\n",
    "ch = Turing.sample(prefernce_learning(hcat(inputs...), appraisals, 1.0), Turing.HMC(0.05, 10), 1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumstats = Turing.summarize(ch, Turing.mean, Turing.std)\n",
    "mθ, vθ   = sumstats.nt.mean, sumstats.nt.std;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "starting-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = Turing.MCMCChains.group(ch, :nn_params).value;\n",
    "# Find the index that provided the highest log posterior in the chain.\n",
    "_, i = findmax(ch[:lp])\n",
    "i = i.I[1]\n",
    "θ = theta[i, :];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "rocky-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for n in 1:length(appraisals)\n",
    "    push!(predictions, nn_forward(inputs[n], θ))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "revised-adobe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for errors on training set\n",
    "appraisals_ = [rand(Distributions.Bernoulli(p[1])) for p in predictions]\n",
    "err = sum(abs.(appraisals .- appraisals_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-enlargement",
   "metadata": {},
   "source": [
    "## Planning\n",
    "Few things must be said about the planning stage. \n",
    "First of all, the idea of planning is a reverse problem to prefernce learning. \n",
    "Given the parameters of neural network, the goal prior for the appraisal (1.0) and an informative prior for the future context (we have an idea of how the environment evolves), we want to infer the most suitable gains.\n",
    "The evolution of the context will be based on HMM model, where the observations are \n",
    "\n",
    "For illustration purposes, we will first run the inference algorithm to obtain **z** and **x**. Secondly, we run our agent that proposes gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "sublime-honolulu",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample_gains (generic function with 2 methods)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: both Flux and Distributions export \"params\"; uses of it in module Main must be qualified\n"
     ]
    }
   ],
   "source": [
    "# infer gains\n",
    "function sample_gains(context, nn_params, N=1000)\n",
    "    ch = Turing.sample(planning(nn_params, [1.0], context), Turing.HMC(0.01, 4), N);\n",
    "    gains_context = Turing.MCMCChains.group(ch, :gs).value\n",
    "    # Find the index that provided the highest log posterior in the chain.\n",
    "    _, i = findmax(ch[:lp])\n",
    "    i = i.I[1]\n",
    "    Float64.(gains_context[i, :])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "handmade-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = get_sounds_fn(\"sound/AIDA/test/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "other-damages",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp09_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:04:12\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp10_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:04:19\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp11_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:05:01\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp12_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:04:01\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp13_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:17\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp14_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:43\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp15_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:42\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp16_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:02:57\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp17_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:01\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp18_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:04\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp19_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:49\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp20_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:48\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# obtain HA output for test set (data for acting)\n",
    "using JLD\n",
    "# r for recovered\n",
    "for test_file in test_files\n",
    "    println(test_file)\n",
    "    speech, fs = WAV.wavread(test_file)\n",
    "    speech_seg = get_frames(speech, fs)\n",
    "    # choose priors\n",
    "    priors_eta = occursin(\"babble\", test_file) ? (bblmη_arr, bblvη_arr) : (trmη_arr, trvη_arr)\n",
    "    priors_tau = occursin(\"babble\", test_file) ? bblτ_arr : trτ_arr\n",
    "    \n",
    "    # make sure that 1D of priors and speech_seg are equal\n",
    "    if size(priors_eta, 1) != size(speech_seg, 1)\n",
    "        totseg = size(speech_seg, 1)\n",
    "        priors_eta_m, priors_eta_v, priors_tau = prior_to_priors(priors_eta[1][1, :]', priors_eta[2][1, :, :], priors_tau[1], totseg)\n",
    "        priors_eta = priors_eta_m, priors_eta_v\n",
    "    end\n",
    "    rmz, rvz, rmθ, rvθ, rγ, rmx, rvx, rmη, rvη, rτ, fe, rmo = HA_algorithm(speech_seg, priors_eta, priors_tau, 10, 2, 10);\n",
    "    \n",
    "    JLD.save(\"sound/AIDA/separated_jld/test/\"*test_file[findfirst(\"sp\", test_file)[1]:end][1:end-3]*\"jld\",\n",
    "         \"rmz\", rmz, \"rvz\", rvz, \"rmθ\", rmθ, \"rvθ\", rvθ, \"rγ\", rγ, \n",
    "         \"rmx\", rmx, \"rvx\", rvx, \"rmη\", rmη, \"rvη\", rvη, \"rτ\", rτ,\n",
    "         \"fe\", fe, \"rmo\", rmo, \"filename\", test_file,\n",
    "         \"audio\", speech)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "municipal-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_jlds = get_sounds_fn(\"sound/AIDA/separated_jld/test/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "interior-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here agent plans and learns\n",
    "for test_jld in test_jlds\n",
    "    d = JLD.load(test_jld)\n",
    "    rmz, rmx = d[\"rmz\"], d[\"rmx\"]\n",
    "    filename = d[\"filename\"]\n",
    "    context = occursin(\"babble\", filename) ? 1.0 : 0.0\n",
    "    rz, rx = get_signal(rmz, fs), get_signal(rmx, fs)\n",
    "    # TODO change to the output of flow_nn\n",
    "    gs = sample_gains(context, Float64.(θ))\n",
    "    ha_out = gs[1] .* rz + gs[2] .* rx\n",
    "    # TODO: we can learn here as well. If the user provides a feedback to each proposal, we can feed this information back to our learning function.\n",
    "    WAV.wavwrite(ha_out, fs, \"sound/AIDA/planning/ha_out_$(gs[1])_$(gs[2])_\"*filename[findfirst(\"sp\", filename)[1]:end])\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
