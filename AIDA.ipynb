{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sharing-soundtrack",
   "metadata": {},
   "source": [
    "# Active Inference Design Agent (demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-forest",
   "metadata": {},
   "source": [
    "First, let us generate 10-20 audio signals from HA algorithm with different weights and within different contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "minute-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "using Rocket\n",
    "using ReactiveMP\n",
    "using GraphPPL\n",
    "using Distributions\n",
    "using LinearAlgebra\n",
    "import ProgressMeter\n",
    "using WAV\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "acting-decision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_coupled_learning (generic function with 1 method)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"helpers/aida_segmentation.jl\")\n",
    "include(\"helpers/aida_snr.jl\")\n",
    "include(\"helpers/aida_ar.jl\")\n",
    "include(\"models_inferences.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "labeled-blackberry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-alloy",
   "metadata": {},
   "source": [
    "## Let's obtain priors for the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "august-reporter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babble, fs = wavread(\"sound/AIDA/training/sp01_babble_sn0.wav\")\n",
    "bbl_seg = get_frames(babble, fs)\n",
    "bbl_totseg = size(bbl_seg, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "conservative-questionnaire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, fs = wavread(\"sound/AIDA/training/sp11_train_sn0.wav\")\n",
    "tr_seg = get_frames(train, fs)\n",
    "tr_totseg = size(tr_seg, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "typical-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priors for contexts were obtained through running VAD block\n",
    "# prior for train noise\n",
    "trmη = [0.4132104755921993 -0.16961911841949667]\n",
    "trvη = [0.00972993440498344 -0.0027103005529199036; -0.0027103005529199036 0.004281987640515784]\n",
    "trτ  = (41.0, 0.03644943410647206)\n",
    "trτ  = (41.0, 0.05)\n",
    "\n",
    "# prior for babble noise\n",
    "bblmη = [1.1192255902602752 -0.43086292293101314]\n",
    "bblvη = [0.007837790430663492 -0.005039080815241558; -0.005039080815241558 0.00596413119195013]\n",
    "bblτ  = (41.0, 0.0029780512310493387);\n",
    "bblτ  = (41.0, 0.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-raise",
   "metadata": {},
   "source": [
    "### VAD block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "postal-surveillance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lar_inference_ex (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"models/everything.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "continental-interval",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ar_ssm (generic function with 1 method)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import WAV\n",
    "include(\"helpers/aida_segmentation.jl\")\n",
    "include(\"helpers/aida_ar.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "serial-taste",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_seg = bbl_seg\n",
    "totseg = bbl_totseg\n",
    "# context_seg = tr_seg\n",
    "# totseg = tr_totseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "advisory-winter",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_order = 10\n",
    "vmp_iter = 50\n",
    "fe_ar = zeros(totseg, vmp_iter)\n",
    "fe_gaussian = zeros(totseg, vmp_iter);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "amazing-travel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:08:47\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "ProgressMeter.@showprogress for segnum in 1:totseg\n",
    "    inputs, outputs = ar_ssm(context_seg[segnum, :], ar_order)\n",
    "    γ, τ, θ, x, fe = lar_inference_ex(outputs, ar_order, vmp_iter)\n",
    "    mθ, vθ = mean(θ), cov(θ)\n",
    "    mγ = mean(γ)\n",
    "    fe_ar[segnum, :] = fe\n",
    "    \n",
    "    x, γ, fe = inference_gaussian(outputs, vmp_iter, 1e4)\n",
    "    mx, vx = mean(x), cov(x)\n",
    "    mγ = mean(γ)\n",
    "    fe_gaussian[segnum, :] = fe\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "wooden-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect silent frames based on model comparison\n",
    "vad = [x[end] < y[end] for (x, y) in zip(eachrow(fe_ar), eachrow(fe_gaussian))];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "innovative-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsegs = findall(isequal(1), vad)\n",
    "nsegs = findall(isequal(0), vad);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "adverse-wales",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.938993996124832"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv(var(sum([context_seg[nseg, :] for nseg in nsegs])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "contemporary-begin",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:06\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "cmx, cvx, cmη, cvη, cτ = lar_batch_learning(hcat([context_seg[nseg, :] for nseg in nsegs]...)', 2, 10, 1e-12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "focused-league",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1192255902602752 -0.43086292293101314], [0.007837790430663492 -0.005039080815241558; -0.005039080815241558 0.00596413119195013], , (41.0, 0.0029780512310493387)\n"
     ]
    }
   ],
   "source": [
    "println(\"$(mean(cmη, dims=1)), $(mean(cvη, dims=1)[1, :, :]), , $((cτ[end][1], cτ[end][2]))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "popular-cooperation",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: cmη not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: cmη not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[8]:3",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "# Priors for contexts were obtained through running VAD block\n",
    "# prior for train noise\n",
    "trmη = mean(cmη, dims=1)\n",
    "trvη = mean(cvη, dims=1)[1, :, :]\n",
    "trτ  = (cτ[end][1], cτ[end][2])\n",
    "\n",
    "# prior for babble noise\n",
    "bblmη = mean(cmη, dims=1)\n",
    "bblvη = mean(cvη, dims=1)[1, :, :]\n",
    "bblτ  = (cτ[end][1], cτ[end][2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-samoa",
   "metadata": {},
   "source": [
    "## Source seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "optional-manchester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prior_to_priors (generic function with 1 method)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coupled AR model is deisgned to work with time-varying priors for both speech and environmental noise\n",
    "# prior_to_priors map \"static\" priors to the corresponding matrices with equal elements\n",
    "function prior_to_priors(mη, vη, τ, totseg)\n",
    "    ar_order = size(mη, 2)\n",
    "    rmη = zeros(totseg, ar_order)\n",
    "    rvη = zeros(totseg, ar_order, ar_order)\n",
    "    for segnum in 1:totseg\n",
    "        rmη[segnum, :], rvη[segnum, :, :] = reshape(mη, (ar_order,)), vη\n",
    "    end\n",
    "    priors_eta = rmη, rvη\n",
    "    priors_tau = [τ for _ in 1:totseg]\n",
    "    priors_eta[1], priors_eta[2], priors_tau\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "persistent-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "trmη_arr, trvη_arr, trτ_arr = prior_to_priors(trmη, trvη, trτ, tr_totseg)\n",
    "bblmη_arr, bblvη_arr, bblτ_arr = prior_to_priors(bblmη, bblvη, bblτ, bbl_totseg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "elect-digest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agent_weigths (generic function with 1 method)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is dumb function that generates weights = [1.0, 0.0]\n",
    "# agent will be here\n",
    "function agent_weigths(sources_num)\n",
    "    w = zeros(sources_num); w[1] = 1.0\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "forbidden-watch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HA_algorithm (generic function with 1 method)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function HA_algorithm(segments, priors_η, priors_τ, ar_1_order, ar_2_order, vmp_its)\n",
    "    \"\"\"Source seperation based on coupled AR model. Inference is performed in batch manner\n",
    "\n",
    "       segments: segmented audio signal\n",
    "       priors_η:   matrix of means and covariances of AR coefficients (see output formal of prior_to_priors\n",
    "       priors_τ:   array of tupes contatining the prior of environmental noise precision\n",
    "       ar_1_order: order of speech signal\n",
    "       ar_2_order: order of environmental noise signal\n",
    "       vmp_its:    number of variational iterations\n",
    "    \"\"\"\n",
    "    n_sources = 2\n",
    "    totseg = size(segments, 1)\n",
    "    l      = size(segments, 2) # dimensionality of the buffer\n",
    "    \n",
    "    rmx = zeros(totseg, l)\n",
    "    rvx = zeros(totseg, l)\n",
    "    rmθ = zeros(totseg, ar_1_order)\n",
    "    rvθ = zeros(totseg, ar_1_order, ar_1_order)\n",
    "    rγ = fill(tuple(.0, .0), totseg)\n",
    "    \n",
    "    rmz = zeros(totseg, l)\n",
    "    rvz = zeros(totseg, l)\n",
    "    rmη = zeros(totseg, ar_2_order)\n",
    "    rvη = zeros(totseg, ar_2_order, ar_2_order)\n",
    "    rτ = fill(tuple(.0, .0), totseg)\n",
    "    \n",
    "    fe  = zeros(totseg, vmp_its)\n",
    "    \n",
    "    rmo = zeros(totseg, l)\n",
    "    \n",
    "    # agent proposes weights according to its beliefs\n",
    "    weights                           = agent_weigths(n_sources)\n",
    "    ProgressMeter.@showprogress for segnum in 1:totseg\n",
    "        prior_η                           = (priors_η[1][segnum, :], priors_η[2][segnum, :, :])\n",
    "        prior_τ                           = priors_τ[segnum]\n",
    "        γ, θ, zs, τ, η, xs, fe[segnum, :] = coupled_inference(segments[segnum, :], prior_η, prior_τ, ar_1_order, ar_2_order, vmp_its)\n",
    "        mz, vz                            = mean.(zs), cov.(zs)\n",
    "        mθ, vθ                            = mean(θ), cov(θ)\n",
    "        rmz[segnum, :], rvz[segnum, :]    = first.(mz), first.(vz)\n",
    "        rmθ[segnum, :], rvθ[segnum, :, :] = mθ, vθ\n",
    "        rγ[segnum]                        = shape(γ), rate(γ)\n",
    "        \n",
    "        mx, vx                            = mean.(xs), cov.(xs)\n",
    "        mη, vη                            = mean(η), cov(η)\n",
    "        rmx[segnum, :], rvx[segnum, :]    = first.(mx), first.(vx)\n",
    "        rmη[segnum, :], rvη[segnum, :, :] = mη, vη\n",
    "        rτ[segnum]                        = shape(τ), rate(τ)\n",
    "        \n",
    "        # HA part\n",
    "        speech = rmz[segnum, :] .* weights[1]\n",
    "        noise  = rmx[segnum, :] .* weights[2]\n",
    "        rmo[segnum, :] = speech .+ noise\n",
    "    end\n",
    "    rmz, rvz, rmθ, rvθ, rγ, rmx, rvx, rmη, rvη, rτ, fe, rmo\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-providence",
   "metadata": {},
   "source": [
    "#### Obtain the outputs from HA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "decent-mining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_sounds_fn (generic function with 1 method)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_sounds_fn(dir_name)\n",
    "    file_names = []\n",
    "    for (root, dirs, files) in walkdir(dir_name)\n",
    "        for file in files\n",
    "            push!(file_names, joinpath(root, file)) # path to files\n",
    "        end\n",
    "    end\n",
    "    file_names\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bottom-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = get_sounds_fn(\"sound/AIDA/training/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "destroyed-warner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp08_babble_sn0.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "380×80 Matrix{Float64}:\n",
       "  0.0542314   0.0467544    0.00265511  …  -0.126011    -0.206244\n",
       "  0.033723    0.0573443    0.0773339      -0.0227058   -0.0657979\n",
       "  0.140538    0.106693     0.0360118       0.146092     0.0616169\n",
       "  0.0662252  -0.018128    -0.032075       -0.0811182    0.0431227\n",
       "  0.0480972   0.0445875    0.0498367      -0.0253609   -0.0185553\n",
       " -0.0292673  -0.0645466   -0.103793    …   0.14066      0.123875\n",
       " -0.0381481  -0.0107425    0.0104678       0.0936613    0.0746178\n",
       " -0.028077   -0.0843837   -0.0903348      -0.036256    -0.0307016\n",
       "  0.0492569   0.0639973    0.0399182       0.050264    -0.0648824\n",
       "  0.0670797   0.00317392   0.00521867      0.044496     0.0498978\n",
       " -0.101077   -0.0573138   -0.014069    …  -0.0697348   -0.0841395\n",
       "  0.0554827   0.0452589   -0.0309763       0.156255     0.0937223\n",
       " -0.0675069   0.0357677    0.0458998      -0.156713    -0.0555437\n",
       "  ⋮                                    ⋱               \n",
       "  0.0116581  -0.00210578  -0.0115665      -0.0350963   -0.0211493\n",
       " -0.0178533  -0.0216987   -0.0550859      -0.0550249   -0.0961638\n",
       "  0.0670492   0.0895108    0.0596026   …   0.0244758    0.0264901\n",
       " -0.0633869  -0.0693991   -0.0431227       0.032197     0.0103153\n",
       "  0.0513932   0.0548112    0.0653096      -0.00201422  -0.0256661\n",
       "  0.009064   -0.00671407  -0.00466933      0.0665609    0.028901\n",
       " -0.0514847   0.00173956   0.0195929      -0.0431532   -0.0391552\n",
       "  0.0169378  -0.00396741  -0.0189825   …   0.0251473   -0.0334788\n",
       " -0.0783105  -0.120151    -0.0912198       0.0107425   -0.0112003\n",
       " -0.0747703  -0.0825526   -0.0419324       0.0646992    0.10184\n",
       "  0.0134587   0.0128178    0.0318918       0.0203558    0.0274667\n",
       " -0.0343638  -0.0481277   -0.0563677       0.0          0.0"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file = training_files[8]\n",
    "println(training_file)\n",
    "speech, fs = WAV.wavread(training_file)\n",
    "speech_seg = get_frames(speech, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "optical-parcel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp08_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:39\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp09_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:46\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp10_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:20\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp11_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:39\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp12_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:26\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp13_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:10\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp14_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:39\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp15_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:41\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp16_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:02:54\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp17_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp18_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:02:51\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp19_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:20\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp20_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:14\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "import JLD\n",
    "# r for recovered\n",
    "for training_file in training_files\n",
    "    println(training_file)\n",
    "    speech, fs = WAV.wavread(training_file)\n",
    "    speech_seg = get_frames(speech, fs)\n",
    "    # choose priors\n",
    "    priors_eta = occursin(\"babble\", training_file) ? (bblmη_arr, bblvη_arr) : (trmη_arr, trvη_arr)\n",
    "    priors_tau = occursin(\"babble\", training_file) ? bblτ_arr : trτ_arr\n",
    "    # make sure that 1D of priors and speech_seg are equal\n",
    "    if size(priors_eta, 1) != size(speech_seg, 1)\n",
    "        totseg = size(speech_seg, 1)\n",
    "        priors_eta_m, priors_eta_v, priors_tau = prior_to_priors(priors_eta[1][1, :]', priors_eta[2][1, :, :], priors_tau[1], totseg)\n",
    "        priors_eta = priors_eta_m, priors_eta_v\n",
    "    end\n",
    "    rmz, rvz, rmθ, rvθ, rγ, rmx, rvx, rmη, rvη, rτ, fe, rmo = HA_algorithm(speech_seg, priors_eta, priors_tau, 10, 2, 10);\n",
    "    \n",
    "    JLD.save(\"sound/AIDA/separated_jld/training/\"*training_file[findfirst(\"sp\", training_file)[1]:end][1:end-3]*\"jld\",\n",
    "         \"rmz\", rmz, \"rvz\", rvz, \"rmθ\", rmθ, \"rvθ\", rvθ, \"rγ\", rγ, \n",
    "         \"rmx\", rmx, \"rvx\", rvx, \"rmη\", rmη, \"rvη\", rvη, \"rτ\", rτ,\n",
    "         \"fe\", fe, \"rmo\", rmo, \"filename\", training_file,\n",
    "         \"audio\", speech)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-documentary",
   "metadata": {},
   "source": [
    "### Preference learning stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-death",
   "metadata": {},
   "source": [
    "#### Generate outputs of HA from JLD files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "elect-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_jlds = get_sounds_fn(\"sound/AIDA/separated_jld/training/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "structural-rescue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Vector{Float64}}:\n",
       " [2.0, 1.0]\n",
       " [1.0, 0.0]\n",
       " [0.5, 0.5]\n",
       " [0.9, 0.3]\n",
       " [2.5, 1.0]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_weights = [[2.0, 1.0], [1.0, 0.0], [0.5, 0.5], [0.9, 0.3], [2.5, 1.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "mineral-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "for training_jld in training_jlds\n",
    "    d = JLD.load(training_jld)\n",
    "    rmz, rmx = d[\"rmz\"], d[\"rmx\"]\n",
    "    filename = d[\"filename\"]\n",
    "    rz, rx = get_signal(rmz, fs), get_signal(rmx, fs)\n",
    "    whgs = rand(agent_weights)\n",
    "    ha_out = whgs[1] .* rz + whgs[2] .* rx\n",
    "    \n",
    "    WAV.wavwrite(ha_out, fs, \"sound/AIDA/preference_learning/ha_out_$(whgs[1])_$(whgs[2])_\"*filename[findfirst(\"sp\", filename)[1]:end])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-press",
   "metadata": {},
   "source": [
    "#### Create pairs weights<->appraisals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recorded weights and appraisals \n",
    "weights = [[0.5, 0.5], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [2.0, 1.0], [2.0, 1.0], [2.5, 1.0], [2.5, 1.0], [2.5, 1.0]]\n",
    "appraisals = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "blank-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "prl_files = get_sounds_fn(\"sound/AIDA/preference_learning/\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-flooring",
   "metadata": {},
   "source": [
    "User gets to listen new audio samples with proposed weights. After each listening he/she evaluates the performance of HA output by binary feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "every-snapshot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[[0.5, 0.5], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [2.0, 1.0], [2.0, 1.0], [2.5, 1.0], [2.5, 1.0], [2.5, 1.0]]\n",
      "Any[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "println(weights)\n",
    "println(appraisals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "muslim-marble",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0.0\n"
     ]
    }
   ],
   "source": [
    "nnum = 8 # prefix for weights\n",
    "appraisals = []\n",
    "weights = []\n",
    "for prl_file in prl_files\n",
    "    \n",
    "    WAV.wavplay(prl_file)\n",
    "    println(\"How's HA output 1, 0 ?\")\n",
    "    appraisal = readline()\n",
    "    push!(appraisals, parse(Float64, appraisal))\n",
    "    \n",
    "    # extract weights routine\n",
    "    pref_id = findfirst(\"out_\", prl_file)[end]\n",
    "    weights_str = prl_file[pref_id+1:pref_id+nnum-1]\n",
    "    push!(weights, parse.(Float64, split(weights_str, \"_\")))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = get_sounds_fn(\"sound/AIDA/training/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain HA output for test set (data for acting)\n",
    "import JLD\n",
    "# r for recovered\n",
    "for test_file in test_files\n",
    "    println(test_file)\n",
    "    speech, fs = WAV.wavread(training_file)\n",
    "    speech_seg = get_frames(speech, fs)\n",
    "    # choose priors\n",
    "    priors_eta = occursin(\"babble\", training_file) ? (bblmη_arr, bblvη_arr) : (trmη_arr, trvη_arr)\n",
    "    priors_tau = occursin(\"babble\", training_file) ? bblτ_arr : trτ_arr\n",
    "    rmz, rvz, rmθ, rvθ, rγ, rmx, rvx, rmη, rvη, rτ, fe, rmo = HA_algorithm(speech_seg, priors_eta, priors_tau, 10, 2, 10);\n",
    "    \n",
    "    JLD.save(\"sound/AIDA/separated_jld/test/\"*test_file[findfirst(\"sp\", test_file)[1]:end][1:end-3]*\"jld\",\n",
    "         \"rmz\", rmz, \"rvz\", rvz, \"rmθ\", rmθ, \"rvθ\", rvθ, \"rγ\", rγ, \n",
    "         \"rmx\", rmx, \"rvx\", rvx, \"rmη\", rmη, \"rvη\", rvη, \"rτ\", rτ,\n",
    "         \"fe\", fe, \"rmo\", rmo, \"filename\", test_file,\n",
    "         \"audio\", speech)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_jlds = get_sounds_fn(\"sound/AIDA/separated_jld/test/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here agent plans and learns\n",
    "for test_jld in test_jlds\n",
    "    d = JLD.load(test_jld)\n",
    "    rmz, rmx = d[\"rmz\"], d[\"rmx\"]\n",
    "    filename = d[\"filename\"]\n",
    "    rz, rx = get_signal(rmz, fs), get_signal(rmx, fs)\n",
    "    whgs = rand(agent_weights)\n",
    "    ha_out = whgs[1] .* rz + whgs[2] .* rx\n",
    "    # TODO: active loop\n",
    "    WAV.wavwrite(ha_out, fs, \"sound/AIDA/planning/ha_out_$(whgs[1])_$(whgs[2])_\"*filename[findfirst(\"sp\", filename)[1]:end])\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
