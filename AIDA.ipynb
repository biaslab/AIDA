{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "automotive-relation",
   "metadata": {},
   "source": [
    "# Active Inference Design Agent (demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-afternoon",
   "metadata": {},
   "source": [
    "First, let us generate 10-20 audio signals from HA algorithm with different gains and within different contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "marine-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "using Rocket\n",
    "using ReactiveMP\n",
    "using GraphPPL\n",
    "using Distributions\n",
    "using LinearAlgebra\n",
    "import ProgressMeter\n",
    "using WAV\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unexpected-geology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_coupled_learning (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"helpers/aida_segmentation.jl\")\n",
    "include(\"helpers/aida_snr.jl\")\n",
    "include(\"helpers/aida_ar.jl\")\n",
    "include(\"models_inferences.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "valued-protection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-priority",
   "metadata": {},
   "source": [
    "## Let's obtain priors for the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "meaningful-reaction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babble, fs = wavread(\"sound/AIDA/training/sp01_babble_sn0.wav\")\n",
    "bbl_seg = get_frames(babble, fs)\n",
    "bbl_totseg = size(bbl_seg, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "voluntary-lincoln",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, fs = wavread(\"sound/AIDA/training/sp11_train_sn0.wav\")\n",
    "tr_seg = get_frames(train, fs)\n",
    "tr_totseg = size(tr_seg, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "understood-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priors for contexts were obtained through running VAD block\n",
    "# prior for train noise\n",
    "trmη = [0.4132104755921993 -0.16961911841949667]\n",
    "trvη = [0.00972993440498344 -0.0027103005529199036; -0.0027103005529199036 0.004281987640515784]\n",
    "trτ  = (41.0, 0.03644943410647206)\n",
    "trτ  = (41.0, 0.05)\n",
    "\n",
    "# prior for babble noise\n",
    "bblmη = [1.1192255902602752 -0.43086292293101314]\n",
    "bblvη = [0.007837790430663492 -0.005039080815241558; -0.005039080815241558 0.00596413119195013]\n",
    "bblτ  = (41.0, 0.0029780512310493387);\n",
    "bblτ  = (41.0, 0.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-count",
   "metadata": {},
   "source": [
    "### VAD block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "immediate-vanilla",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lar_inference_ex (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"models/everything.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "combined-courtesy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ar_ssm (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import WAV\n",
    "include(\"helpers/aida_segmentation.jl\")\n",
    "include(\"helpers/aida_ar.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "separate-obligation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_seg = bbl_seg\n",
    "totseg = bbl_totseg\n",
    "# context_seg = tr_seg\n",
    "# totseg = tr_totseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "conditional-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_order = 10\n",
    "vmp_iter = 50\n",
    "fe_ar = zeros(totseg, vmp_iter)\n",
    "fe_gaussian = zeros(totseg, vmp_iter);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "handled-superintendent",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:08:47\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "ProgressMeter.@showprogress for segnum in 1:totseg\n",
    "    inputs, outputs = ar_ssm(context_seg[segnum, :], ar_order)\n",
    "    γ, τ, θ, x, fe = lar_inference_ex(outputs, ar_order, vmp_iter)\n",
    "    mθ, vθ = mean(θ), cov(θ)\n",
    "    mγ = mean(γ)\n",
    "    fe_ar[segnum, :] = fe\n",
    "    \n",
    "    x, γ, fe = inference_gaussian(outputs, vmp_iter, 1e4)\n",
    "    mx, vx = mean(x), cov(x)\n",
    "    mγ = mean(γ)\n",
    "    fe_gaussian[segnum, :] = fe\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "orange-bachelor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect silent frames based on model comparison\n",
    "vad = [x[end] < y[end] for (x, y) in zip(eachrow(fe_ar), eachrow(fe_gaussian))];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "copyrighted-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsegs = findall(isequal(1), vad)\n",
    "nsegs = findall(isequal(0), vad);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "chief-turner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.938993996124832"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv(var(sum([context_seg[nseg, :] for nseg in nsegs])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "special-villa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:06\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "cmx, cvx, cmη, cvη, cτ = lar_batch_learning(hcat([context_seg[nseg, :] for nseg in nsegs]...)', 2, 10, 1e-12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ready-season",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1192255902602752 -0.43086292293101314], [0.007837790430663492 -0.005039080815241558; -0.005039080815241558 0.00596413119195013], , (41.0, 0.0029780512310493387)\n"
     ]
    }
   ],
   "source": [
    "println(\"$(mean(cmη, dims=1)), $(mean(cvη, dims=1)[1, :, :]), , $((cτ[end][1], cτ[end][2]))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "engaged-elements",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: cmη not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: cmη not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[10]:3",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "# Priors for contexts were obtained through running VAD block\n",
    "trmη = mean(cmη, dims=1)\n",
    "trvη = mean(cvη, dims=1)[1, :, :]\n",
    "trτ  = (cτ[end][1], cτ[end][2])\n",
    "\n",
    "# prior for babble noise\n",
    "bblmη = mean(cmη, dims=1)\n",
    "bblvη = mean(cvη, dims=1)[1, :, :]\n",
    "bblτ  = (cτ[end][1], cτ[end][2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-minute",
   "metadata": {},
   "source": [
    "## Source seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eight-graph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prior_to_priors (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coupled AR model is deisgned to work with time-varying priors for both speech and environmental noise\n",
    "# prior_to_priors map \"static\" priors to the corresponding matrices with equal elements\n",
    "function prior_to_priors(mη, vη, τ, totseg)\n",
    "    ar_order = size(mη, 2)\n",
    "    rmη = zeros(totseg, ar_order)\n",
    "    rvη = zeros(totseg, ar_order, ar_order)\n",
    "    for segnum in 1:totseg\n",
    "        rmη[segnum, :], rvη[segnum, :, :] = reshape(mη, (ar_order,)), vη\n",
    "    end\n",
    "    priors_eta = rmη, rvη\n",
    "    priors_tau = [τ for _ in 1:totseg]\n",
    "    priors_eta[1], priors_eta[2], priors_tau\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "crazy-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "trmη_arr, trvη_arr, trτ_arr = prior_to_priors(trmη, trvη, trτ, tr_totseg)\n",
    "bblmη_arr, bblvη_arr, bblτ_arr = prior_to_priors(bblmη, bblvη, bblτ, bbl_totseg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "curious-respondent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agent_gains (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is dumb function that generates gains = [1.0, 0.0]\n",
    "# agent will be here\n",
    "function agent_gains(sources_num)\n",
    "    gs = zeros(sources_num); w[1] = 1.0\n",
    "    return gs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "comparative-sculpture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HA_algorithm (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function HA_algorithm(segments, priors_η, priors_τ, ar_1_order, ar_2_order, vmp_its)\n",
    "    \"\"\"Source seperation based on coupled AR model. Inference is performed in batch manner\n",
    "\n",
    "       segments: segmented audio signal\n",
    "       priors_η:   matrix of means and covariances of AR coefficients (see output formal of prior_to_priors\n",
    "       priors_τ:   array of tupes contatining the prior of environmental noise precision\n",
    "       ar_1_order: order of speech signal\n",
    "       ar_2_order: order of environmental noise signal\n",
    "       vmp_its:    number of variational iterations\n",
    "    \"\"\"\n",
    "    n_sources = 2\n",
    "    totseg = size(segments, 1)\n",
    "    l      = size(segments, 2) # dimensionality of the buffer\n",
    "    \n",
    "    rmx = zeros(totseg, l)\n",
    "    rvx = zeros(totseg, l)\n",
    "    rmθ = zeros(totseg, ar_1_order)\n",
    "    rvθ = zeros(totseg, ar_1_order, ar_1_order)\n",
    "    rγ = fill(tuple(.0, .0), totseg)\n",
    "    \n",
    "    rmz = zeros(totseg, l)\n",
    "    rvz = zeros(totseg, l)\n",
    "    rmη = zeros(totseg, ar_2_order)\n",
    "    rvη = zeros(totseg, ar_2_order, ar_2_order)\n",
    "    rτ = fill(tuple(.0, .0), totseg)\n",
    "    \n",
    "    fe  = zeros(totseg, vmp_its)\n",
    "    \n",
    "    rmo = zeros(totseg, l)\n",
    "    \n",
    "    # agent proposes gains according to its beliefs\n",
    "    gains                           = agent_gains(n_sources)\n",
    "    ProgressMeter.@showprogress for segnum in 1:totseg\n",
    "        prior_η                           = (priors_η[1][segnum, :], priors_η[2][segnum, :, :])\n",
    "        prior_τ                           = priors_τ[segnum]\n",
    "        γ, θ, zs, τ, η, xs, fe[segnum, :] = coupled_inference(segments[segnum, :], prior_η, prior_τ, ar_1_order, ar_2_order, vmp_its)\n",
    "        mz, vz                            = mean.(zs), cov.(zs)\n",
    "        mθ, vθ                            = mean(θ), cov(θ)\n",
    "        rmz[segnum, :], rvz[segnum, :]    = first.(mz), first.(vz)\n",
    "        rmθ[segnum, :], rvθ[segnum, :, :] = mθ, vθ\n",
    "        rγ[segnum]                        = shape(γ), rate(γ)\n",
    "        \n",
    "        mx, vx                            = mean.(xs), cov.(xs)\n",
    "        mη, vη                            = mean(η), cov(η)\n",
    "        rmx[segnum, :], rvx[segnum, :]    = first.(mx), first.(vx)\n",
    "        rmη[segnum, :], rvη[segnum, :, :] = mη, vη\n",
    "        rτ[segnum]                        = shape(τ), rate(τ)\n",
    "        \n",
    "        # HA part\n",
    "        speech = rmz[segnum, :] .* gains[1]\n",
    "        noise  = rmx[segnum, :] .* gains[2]\n",
    "        rmo[segnum, :] = speech .+ noise\n",
    "    end\n",
    "    rmz, rvz, rmθ, rvθ, rγ, rmx, rvx, rmη, rvη, rτ, fe, rmo\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-lobby",
   "metadata": {},
   "source": [
    "#### Obtain the outputs from HA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beginning-child",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_sounds_fn (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_sounds_fn(dir_name)\n",
    "    file_names = []\n",
    "    for (root, dirs, files) in walkdir(dir_name)\n",
    "        for file in files\n",
    "            push!(file_names, joinpath(root, file)) # path to files\n",
    "        end\n",
    "    end\n",
    "    file_names\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dirty-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = get_sounds_fn(\"sound/AIDA/training/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "naval-documentation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp08_babble_sn0.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "380×80 Matrix{Float64}:\n",
       "  0.0542314   0.0467544    0.00265511  …  -0.126011    -0.206244\n",
       "  0.033723    0.0573443    0.0773339      -0.0227058   -0.0657979\n",
       "  0.140538    0.106693     0.0360118       0.146092     0.0616169\n",
       "  0.0662252  -0.018128    -0.032075       -0.0811182    0.0431227\n",
       "  0.0480972   0.0445875    0.0498367      -0.0253609   -0.0185553\n",
       " -0.0292673  -0.0645466   -0.103793    …   0.14066      0.123875\n",
       " -0.0381481  -0.0107425    0.0104678       0.0936613    0.0746178\n",
       " -0.028077   -0.0843837   -0.0903348      -0.036256    -0.0307016\n",
       "  0.0492569   0.0639973    0.0399182       0.050264    -0.0648824\n",
       "  0.0670797   0.00317392   0.00521867      0.044496     0.0498978\n",
       " -0.101077   -0.0573138   -0.014069    …  -0.0697348   -0.0841395\n",
       "  0.0554827   0.0452589   -0.0309763       0.156255     0.0937223\n",
       " -0.0675069   0.0357677    0.0458998      -0.156713    -0.0555437\n",
       "  ⋮                                    ⋱               \n",
       "  0.0116581  -0.00210578  -0.0115665      -0.0350963   -0.0211493\n",
       " -0.0178533  -0.0216987   -0.0550859      -0.0550249   -0.0961638\n",
       "  0.0670492   0.0895108    0.0596026   …   0.0244758    0.0264901\n",
       " -0.0633869  -0.0693991   -0.0431227       0.032197     0.0103153\n",
       "  0.0513932   0.0548112    0.0653096      -0.00201422  -0.0256661\n",
       "  0.009064   -0.00671407  -0.00466933      0.0665609    0.028901\n",
       " -0.0514847   0.00173956   0.0195929      -0.0431532   -0.0391552\n",
       "  0.0169378  -0.00396741  -0.0189825   …   0.0251473   -0.0334788\n",
       " -0.0783105  -0.120151    -0.0912198       0.0107425   -0.0112003\n",
       " -0.0747703  -0.0825526   -0.0419324       0.0646992    0.10184\n",
       "  0.0134587   0.0128178    0.0318918       0.0203558    0.0274667\n",
       " -0.0343638  -0.0481277   -0.0563677       0.0          0.0"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file = training_files[8]\n",
    "println(training_file)\n",
    "speech, fs = WAV.wavread(training_file)\n",
    "speech_seg = get_frames(speech, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "threatened-madness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp08_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:39\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp09_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:46\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp10_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:20\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp11_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:39\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp12_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:26\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp13_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:10\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp14_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:39\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp15_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:41\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp16_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:02:54\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp17_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp18_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:02:51\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp19_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:20\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/training/sp20_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:14\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "import JLD\n",
    "# r for recovered\n",
    "for training_file in training_files\n",
    "    println(training_file)\n",
    "    speech, fs = WAV.wavread(training_file)\n",
    "    speech_seg = get_frames(speech, fs)\n",
    "    # choose priors\n",
    "    priors_eta = occursin(\"babble\", training_file) ? (bblmη_arr, bblvη_arr) : (trmη_arr, trvη_arr)\n",
    "    priors_tau = occursin(\"babble\", training_file) ? bblτ_arr : trτ_arr\n",
    "    # make sure that 1D of priors and speech_seg are equal\n",
    "    if size(priors_eta, 1) != size(speech_seg, 1)\n",
    "        totseg = size(speech_seg, 1)\n",
    "        priors_eta_m, priors_eta_v, priors_tau = prior_to_priors(priors_eta[1][1, :]', priors_eta[2][1, :, :], priors_tau[1], totseg)\n",
    "        priors_eta = priors_eta_m, priors_eta_v\n",
    "    end\n",
    "    rmz, rvz, rmθ, rvθ, rγ, rmx, rvx, rmη, rvη, rτ, fe, rmo = HA_algorithm(speech_seg, priors_eta, priors_tau, 10, 2, 10);\n",
    "    \n",
    "    JLD.save(\"sound/AIDA/separated_jld/training/\"*training_file[findfirst(\"sp\", training_file)[1]:end][1:end-3]*\"jld\",\n",
    "         \"rmz\", rmz, \"rvz\", rvz, \"rmθ\", rmθ, \"rvθ\", rvθ, \"rγ\", rγ, \n",
    "         \"rmx\", rmx, \"rvx\", rvx, \"rmη\", rmη, \"rvη\", rvη, \"rτ\", rτ,\n",
    "         \"fe\", fe, \"rmo\", rmo, \"filename\", training_file,\n",
    "         \"audio\", speech)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-lesbian",
   "metadata": {},
   "source": [
    "### Preference learning stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-square",
   "metadata": {},
   "source": [
    "#### Generate outputs of HA from JLD files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "handled-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_jlds = get_sounds_fn(\"sound/AIDA/separated_jld/training/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "illegal-aviation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Vector{Float64}}:\n",
       " [2.0, 1.0]\n",
       " [1.0, 0.0]\n",
       " [0.5, 0.5]\n",
       " [0.9, 0.3]\n",
       " [2.5, 1.0]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_gains = [[2.0, 1.0], [1.0, 0.0], [0.5, 0.5], [0.9, 0.3], [2.5, 1.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intensive-qatar",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: training_jlds not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: training_jlds not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[6]:2",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "# this snippet generates new ha outputs\n",
    "for training_jld in training_jlds\n",
    "    d = JLD.load(training_jld)\n",
    "    rmz, rmx = d[\"rmz\"], d[\"rmx\"]\n",
    "    filename = d[\"filename\"]\n",
    "    rz, rx = get_signal(rmz, fs), get_signal(rmx, fs)\n",
    "    whgs = rand(agent_gains)\n",
    "    ha_out = whgs[1] .* rz + whgs[2] .* rx\n",
    "    \n",
    "    WAV.wavwrite(ha_out, fs, \"sound/AIDA/preference_learning/ha_out_$(whgs[1])_$(whgs[2])_\"*filename[findfirst(\"sp\", filename)[1]:end])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-forwarding",
   "metadata": {},
   "source": [
    "#### Create pairs gains<->appraisals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deluxe-buffer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Vector{Float64}:\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 1.0\n",
       " 1.0\n",
       " 0.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recorded gains and appraisals \n",
    "# If you want to generate new pairs, please procceed with listening\n",
    "gains = [[0.5, 0.5], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [2.0, 1.0], [2.0, 1.0], [2.5, 1.0], [2.5, 1.0], [2.5, 1.0]]\n",
    "appraisals = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0];\n",
    "contexts = [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "comparable-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "prl_files = get_sounds_fn(\"sound/AIDA/preference_learning/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "speaking-restaurant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21-element Vector{Any}:\n",
       " \"sound/AIDA/preference_learning/.DS_Store\"\n",
       " \"sound/AIDA/preference_learning/ha_out_0.5_0.5_sp08_babble_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_0.9_0.3_sp01_babble_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_0.9_0.3_sp06_babble_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_0.9_0.3_sp07_babble_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_0.9_0.3_sp09_babble_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_0.9_0.3_sp11_train_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_0.9_0.3_sp12_train_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_0.9_0.3_sp16_train_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_0.9_0.3_sp18_train_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_0.9_0.3_sp20_train_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_1.0_0.0_sp02_babble_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_1.0_0.0_sp04_babble_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_1.0_0.0_sp05_babble_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_1.0_0.0_sp15_train_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_1.0_0.0_sp17_train_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_2.0_1.0_sp13_train_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_2.0_1.0_sp19_train_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_2.5_1.0_sp03_babble_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_2.5_1.0_sp10_babble_sn0.wav\"\n",
       " \"sound/AIDA/preference_learning/ha_out_2.5_1.0_sp14_train_sn0.wav\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prl_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-diana",
   "metadata": {},
   "source": [
    "User gets to listen new audio samples with proposed gains. After each listening he/she evaluates the performance of HA output by binary feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "separated-berlin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5, 0.5], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [0.9, 0.3], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [2.0, 1.0], [2.0, 1.0], [2.5, 1.0], [2.5, 1.0], [2.5, 1.0]]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "println(gains)\n",
    "println(appraisals)\n",
    "println(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "minor-melissa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's HA output 1, 0 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "stdin>  1\n"
     ]
    }
   ],
   "source": [
    "nnum = 8 # prefix for gains\n",
    "appraisals = []\n",
    "gains = []\n",
    "contexts = []\n",
    "for prl_file in prl_files\n",
    "    \n",
    "    if !occursin(\"wav\", prl_file)\n",
    "        continue\n",
    "    end\n",
    "    WAV.wavplay(prl_file)\n",
    "    println(\"How's HA output 1, 0 ?\")\n",
    "    appraisal = readline()\n",
    "    push!(appraisals, parse(Float64, appraisal))\n",
    "    \n",
    "    # extract gains routine\n",
    "    pref_id = findfirst(\"out_\", prl_file)[end]\n",
    "    gains_str = prl_file[pref_id+1:pref_id+nnum-1]\n",
    "    push!(gains, parse.(Float64, split(gains_str, \"_\")))\n",
    "    \n",
    "    # extract context routine\n",
    "    push!(contexts, occursin(\"babble\", prl_file) ? 1.0 : 0.0)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "enclosed-energy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling ForneyLab [9fc3f58a-c2cc-5bff-9419-6a294fefdca9]\n",
      "└ @ Base loading.jl:1317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "build_est_graph (generic function with 2 methods)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"agent/agent_sampling_mp.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hollow-telling",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:05\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "gains = [g .+ sqrt(0.0001)*randn(length(g)) for g in gains]\n",
    "inputs = [vcat(g, c) for (g, c) in zip(gains, contexts)]\n",
    "N = 10000\n",
    "ch = Turing.sample(prefernce_learning(hcat(inputs...), appraisals, 1.0), Turing.HMC(0.05, 10), N);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sweet-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumstats = Turing.summarize(ch, Turing.mean, Turing.std)\n",
    "mθ, vθ   = sumstats.nt.mean, sumstats.nt.std;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "raising-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all weight and bias parameters.\n",
    "theta = Turing.MCMCChains.group(ch, :nn_params).value;\n",
    "# Find the index that provided the highest log posterior in the chain.\n",
    "_, i = findmax(ch[:lp])\n",
    "i = i.I[1]\n",
    "θ = theta[i, :];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "characteristic-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for n in 1:length(appraisals)\n",
    "    push!(predictions, nn_forward(inputs[n], θ))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sharp-mainstream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Distributions\n",
    "appraisals_ = [rand(Distributions.Bernoulli(p[1])) for p in predictions]\n",
    "err = sum(abs.(appraisals .- appraisals_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "breeding-colombia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "freeEnergyEST (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Planning\n",
    "fl_graph = build_est_graph(2, θ, 1);\n",
    "algo = messagePassingAlgorithm(free_energy=true, id=:EST)\n",
    "src_code = algorithmSourceCode(algo, free_energy=true)\n",
    "eval(Meta.parse(src_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "supported-sport",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching -(::Vector{ForwardDiff.Dual{ForwardDiff.Tag{ForneyLab.var\"#log_joint#307\"{ProbabilityDistribution{Multivariate, GaussianMeanVariance}, ProbabilityDistribution{Multivariate, Function}}, Float64}, Float64, 3}}, ::Float64)\nFor element-wise subtraction, use broadcasting with dot syntax: array .- scalar\n\u001b[0mClosest candidates are:\n\u001b[0m  -(\u001b[91m::IntervalSets.ClosedInterval{T} where T\u001b[39m, ::Union{Number, Dates.AbstractTime}) at /Users/apodusenko/.julia/packages/AxisArrays/IFpjG/src/intervals.jl:52\n\u001b[0m  -(\u001b[91m::Distributions.Distribution{Distributions.Univariate, Distributions.Continuous}\u001b[39m, ::Real) at /Users/apodusenko/.julia/packages/Distributions/Xrm9e/src/univariate/continuous/locationscale.jl:93\n\u001b[0m  -(::Array, \u001b[91m::SparseArrays.AbstractSparseMatrixCSC\u001b[39m) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/SparseArrays/src/sparsematrix.jl:1747\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching -(::Vector{ForwardDiff.Dual{ForwardDiff.Tag{ForneyLab.var\"#log_joint#307\"{ProbabilityDistribution{Multivariate, GaussianMeanVariance}, ProbabilityDistribution{Multivariate, Function}}, Float64}, Float64, 3}}, ::Float64)\nFor element-wise subtraction, use broadcasting with dot syntax: array .- scalar\n\u001b[0mClosest candidates are:\n\u001b[0m  -(\u001b[91m::IntervalSets.ClosedInterval{T} where T\u001b[39m, ::Union{Number, Dates.AbstractTime}) at /Users/apodusenko/.julia/packages/AxisArrays/IFpjG/src/intervals.jl:52\n\u001b[0m  -(\u001b[91m::Distributions.Distribution{Distributions.Univariate, Distributions.Continuous}\u001b[39m, ::Real) at /Users/apodusenko/.julia/packages/Distributions/Xrm9e/src/univariate/continuous/locationscale.jl:93\n\u001b[0m  -(::Array, \u001b[91m::SparseArrays.AbstractSparseMatrixCSC\u001b[39m) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/SparseArrays/src/sparsematrix.jl:1747\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      "  [1] logPdf(dist::ProbabilityDistribution{Univariate, GaussianMeanVariance}, x::Vector{ForwardDiff.Dual{ForwardDiff.Tag{ForneyLab.var\"#log_joint#307\"{ProbabilityDistribution{Multivariate, GaussianMeanVariance}, ProbabilityDistribution{Multivariate, Function}}, Float64}, Float64, 3}})",
      "    @ ForneyLab ~/.julia/dev/ForneyLab/src/factor_nodes/gaussian_mean_variance.jl:68",
      "  [2] (::ForneyLab.var\"#273#274\"{typeof(func1), Message{GaussianMeanVariance, Univariate}})(z::Vector{ForwardDiff.Dual{ForwardDiff.Tag{ForneyLab.var\"#log_joint#307\"{ProbabilityDistribution{Multivariate, GaussianMeanVariance}, ProbabilityDistribution{Multivariate, Function}}, Float64}, Float64, 3}})",
      "    @ ForneyLab ~/.julia/dev/ForneyLab/src/engines/julia/update_rules/nonlinear_sampling.jl:36",
      "  [3] logPdf(dist::ProbabilityDistribution{Multivariate, Function}, x::Vector{ForwardDiff.Dual{ForwardDiff.Tag{ForneyLab.var\"#log_joint#307\"{ProbabilityDistribution{Multivariate, GaussianMeanVariance}, ProbabilityDistribution{Multivariate, Function}}, Float64}, Float64, 3}})",
      "    @ ForneyLab ~/.julia/dev/ForneyLab/src/probability_distribution.jl:118",
      "  [4] (::ForneyLab.var\"#log_joint#307\"{ProbabilityDistribution{Multivariate, GaussianMeanVariance}, ProbabilityDistribution{Multivariate, Function}})(s::Vector{ForwardDiff.Dual{ForwardDiff.Tag{ForneyLab.var\"#log_joint#307\"{ProbabilityDistribution{Multivariate, GaussianMeanVariance}, ProbabilityDistribution{Multivariate, Function}}, Float64}, Float64, 3}})",
      "    @ ForneyLab ~/.julia/dev/ForneyLab/src/engines/julia/update_rules/nonlinear_sampling.jl:322",
      "  [5] vector_mode_dual_eval",
      "    @ ~/.julia/packages/ForwardDiff/QOqCN/src/apiutils.jl:37 [inlined]",
      "  [6] vector_mode_gradient(f::ForneyLab.var\"#log_joint#307\"{ProbabilityDistribution{Multivariate, GaussianMeanVariance}, ProbabilityDistribution{Multivariate, Function}}, x::Vector{Float64}, cfg::ForwardDiff.GradientConfig{ForwardDiff.Tag{ForneyLab.var\"#log_joint#307\"{ProbabilityDistribution{Multivariate, GaussianMeanVariance}, ProbabilityDistribution{Multivariate, Function}}, Float64}, Float64, 3, Vector{ForwardDiff.Dual{ForwardDiff.Tag{ForneyLab.var\"#log_joint#307\"{ProbabilityDistribution{Multivariate, GaussianMeanVariance}, ProbabilityDistribution{Multivariate, Function}}, Float64}, Float64, 3}}})",
      "    @ ForwardDiff ~/.julia/packages/ForwardDiff/QOqCN/src/gradient.jl:106",
      "  [7] gradient(f::Function, x::Vector{Float64}, cfg::ForwardDiff.GradientConfig{ForwardDiff.Tag{ForneyLab.var\"#log_joint#307\"{ProbabilityDistribution{Multivariate, GaussianMeanVariance}, ProbabilityDistribution{Multivariate, Function}}, Float64}, Float64, 3, Vector{ForwardDiff.Dual{ForwardDiff.Tag{ForneyLab.var\"#log_joint#307\"{ProbabilityDistribution{Multivariate, GaussianMeanVariance}, ProbabilityDistribution{Multivariate, Function}}, Float64}, Float64, 3}}}, ::Val{true})",
      "    @ ForwardDiff ~/.julia/packages/ForwardDiff/QOqCN/src/gradient.jl:19",
      "  [8] gradient(f::Function, x::Vector{Float64}, cfg::ForwardDiff.GradientConfig{ForwardDiff.Tag{ForneyLab.var\"#log_joint#307\"{ProbabilityDistribution{Multivariate, GaussianMeanVariance}, ProbabilityDistribution{Multivariate, Function}}, Float64}, Float64, 3, Vector{ForwardDiff.Dual{ForwardDiff.Tag{ForneyLab.var\"#log_joint#307\"{ProbabilityDistribution{Multivariate, GaussianMeanVariance}, ProbabilityDistribution{Multivariate, Function}}, Float64}, Float64, 3}}}) (repeats 2 times)",
      "    @ ForwardDiff ~/.julia/packages/ForwardDiff/QOqCN/src/gradient.jl:17",
      "  [9] (::ForneyLab.var\"#d_log_joint#308\"{ForneyLab.var\"#log_joint#307\"{ProbabilityDistribution{Multivariate, GaussianMeanVariance}, ProbabilityDistribution{Multivariate, Function}}})(s::Vector{Float64})",
      "    @ ForneyLab ~/.julia/dev/ForneyLab/src/engines/julia/update_rules/nonlinear_sampling.jl:323",
      " [10] gradientOptimization(log_joint::ForneyLab.var\"#log_joint#307\"{ProbabilityDistribution{Multivariate, GaussianMeanVariance}, ProbabilityDistribution{Multivariate, Function}}, d_log_joint::ForneyLab.var\"#d_log_joint#308\"{ForneyLab.var\"#log_joint#307\"{ProbabilityDistribution{Multivariate, GaussianMeanVariance}, ProbabilityDistribution{Multivariate, Function}}}, m_initial::Vector{Float64}, step_size::Float64)",
      "    @ ForneyLab ~/.julia/dev/ForneyLab/src/engines/julia/update_rules/nonlinear_sampling.jl:351",
      " [11] prod!(y::ProbabilityDistribution{Multivariate, GaussianMeanVariance}, x::ProbabilityDistribution{Multivariate, Function}, z::ProbabilityDistribution{Multivariate, GaussianMeanPrecision})",
      "    @ ForneyLab ~/.julia/dev/ForneyLab/src/engines/julia/update_rules/nonlinear_sampling.jl:326",
      " [12] prod!(y::ProbabilityDistribution{Multivariate, GaussianMeanVariance}, x::ProbabilityDistribution{Multivariate, Function})",
      "    @ ForneyLab ~/.julia/dev/ForneyLab/src/engines/julia/update_rules/nonlinear_sampling.jl:322",
      " [13] *(x::ProbabilityDistribution{Multivariate, GaussianMeanVariance}, y::ProbabilityDistribution{Multivariate, Function})",
      "    @ ForneyLab ~/.julia/dev/ForneyLab/src/ForneyLab.jl:125",
      " [14] stepEST!(data::Dict{Symbol, AbstractArray{Float64, N} where N}, marginals::Dict{Any, Any}, messages::Vector{Message})",
      "    @ Main ./none:10",
      " [15] stepEST! (repeats 2 times)",
      "    @ ./none:5 [inlined]",
      " [16] top-level scope",
      "    @ In[11]:3",
      " [17] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [18] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "data = Dict(:mu_gs => [0.5, 0.5, 1.0], :Sigma_gs => diageye(3), :y=>[0.9])\n",
    "nn_params = θ\n",
    "marginals = stepEST!(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-prior",
   "metadata": {},
   "source": [
    "## Active Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "perfect-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = get_sounds_fn(\"sound/AIDA/test/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "italian-manchester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp09_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:04:12\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp10_train_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:04:19\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp11_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:05:01\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp12_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:04:01\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp13_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:17\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp14_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:43\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp15_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:42\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp16_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:02:57\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp17_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:01\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp18_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:04\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp19_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:49\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound/AIDA/test/sp20_babble_sn0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:48\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# obtain HA output for test set (data for acting)\n",
    "import JLD\n",
    "# r for recovered\n",
    "for test_file in test_files\n",
    "    println(test_file)\n",
    "    speech, fs = WAV.wavread(test_file)\n",
    "    speech_seg = get_frames(speech, fs)\n",
    "    # choose priors\n",
    "    priors_eta = occursin(\"babble\", test_file) ? (bblmη_arr, bblvη_arr) : (trmη_arr, trvη_arr)\n",
    "    priors_tau = occursin(\"babble\", test_file) ? bblτ_arr : trτ_arr\n",
    "    \n",
    "    # make sure that 1D of priors and speech_seg are equal\n",
    "    if size(priors_eta, 1) != size(speech_seg, 1)\n",
    "        totseg = size(speech_seg, 1)\n",
    "        priors_eta_m, priors_eta_v, priors_tau = prior_to_priors(priors_eta[1][1, :]', priors_eta[2][1, :, :], priors_tau[1], totseg)\n",
    "        priors_eta = priors_eta_m, priors_eta_v\n",
    "    end\n",
    "    rmz, rvz, rmθ, rvθ, rγ, rmx, rvx, rmη, rvη, rτ, fe, rmo = HA_algorithm(speech_seg, priors_eta, priors_tau, 10, 2, 10);\n",
    "    \n",
    "    JLD.save(\"sound/AIDA/separated_jld/test/\"*test_file[findfirst(\"sp\", test_file)[1]:end][1:end-3]*\"jld\",\n",
    "         \"rmz\", rmz, \"rvz\", rvz, \"rmθ\", rmθ, \"rvθ\", rvθ, \"rγ\", rγ, \n",
    "         \"rmx\", rmx, \"rvx\", rvx, \"rmη\", rmη, \"rvη\", rvη, \"rτ\", rτ,\n",
    "         \"fe\", fe, \"rmo\", rmo, \"filename\", test_file,\n",
    "         \"audio\", speech)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acknowledged-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_jlds = get_sounds_fn(\"sound/AIDA/separated_jld/test/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "noble-cooperation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Vector{Any}:\n",
       " \"sound/AIDA/separated_jld/test/sp01_train_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp02_train_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp03_train_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp04_train_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp05_train_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp06_train_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp07_train_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp08_train_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp09_train_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp10_train_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp11_babble_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp12_babble_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp13_babble_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp14_babble_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp15_babble_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp16_babble_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp17_babble_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp18_babble_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp19_babble_sn0.jld\"\n",
       " \"sound/AIDA/separated_jld/test/sp20_babble_sn0.jld\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using JLD\n",
    "test_jlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "faced-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here agent plans and learns\n",
    "for test_jld in test_jlds\n",
    "    d = JLD.load(test_jld)\n",
    "    rmz, rmx = d[\"rmz\"], d[\"rmx\"]\n",
    "    filename = d[\"filename\"]\n",
    "    rz, rx = get_signal(rmz, fs), get_signal(rmx, fs)\n",
    "    gs = rand(agent_gains)\n",
    "    ha_out = gs[1] .* rz + gs[2] .* rx\n",
    "    # TODO: active loop\n",
    "    WAV.wavwrite(ha_out, fs, \"sound/AIDA/planning/ha_out_$(gs[1])_$(gs[2])_\"*filename[findfirst(\"sp\", filename)[1]:end])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-following",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
