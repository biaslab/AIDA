{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User preference learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "\n",
    "using ReactiveMP\n",
    "using Rocket\n",
    "using GraphPPL\n",
    "\n",
    "using Optim\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using PyPlot\n",
    "using StatsFuns: normcdf, norminvcdf\n",
    "using ForwardDiff\n",
    "using BenchmarkTools\n",
    "\n",
    "\n",
    "include(\"../src/environment/user.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify flow model\n",
    "flow_model = FlowModel(2,\n",
    "    (\n",
    "        AdditiveCouplingLayer(PlanarFlow()), # defaults to AdditiveCouplingLayer(PlanarFlow(); permute=true)\n",
    "        # AdditiveCouplingLayer(PlanarFlow()),\n",
    "        AdditiveCouplingLayer(PlanarFlow(); permute=false)\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function flow_classifier(nr_samples::Int64, model::FlowModel, params)\n",
    "    \n",
    "    # initialize variables\n",
    "    x_lat  = randomvar(nr_samples)\n",
    "    y_lat1 = randomvar(nr_samples)\n",
    "    y_lat2 = randomvar(nr_samples)\n",
    "    y      = datavar(Float64, nr_samples)\n",
    "    x      = datavar(Vector{Float64}, nr_samples)\n",
    "\n",
    "    # compile flow model\n",
    "    meta  = FlowMeta(compile(model, params)) # default: FlowMeta(model, Linearization())\n",
    "\n",
    "    # specify observations\n",
    "    for k = 1:nr_samples\n",
    "\n",
    "        # specify latent state\n",
    "        x_lat[k] ~ MvNormalMeanPrecision(x[k], 1e3*diagm(ones(2)))\n",
    "\n",
    "        # specify transformed latent value\n",
    "        y_lat1[k] ~ Flow(x_lat[k]) where { meta = meta }\n",
    "        y_lat2[k] ~ dot(y_lat1[k], [1, 1])\n",
    "\n",
    "        # specify observations\n",
    "        y[k] ~ Probit(y_lat2[k]) # default: where { pipeline = RequireInbound(in = NormalMeanPrecision(0, 1.0)) }\n",
    "\n",
    "    end\n",
    "\n",
    "    # return variables\n",
    "    return x, y\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function inference_flow_classifier(data_y::Array{Float64,1}, data_x::Array{Array{Float64,1},1}, flow_model::FlowModel, params; nr_its=5)\n",
    "    \n",
    "    # fetch number of samples\n",
    "    nr_samples = length(data_y)\n",
    "\n",
    "    # define model\n",
    "    model, (x, y) = flow_classifier(nr_samples, flow_model, params)\n",
    "\n",
    "    # initialize free energy\n",
    "    fe = ScoreActor(eltype(params))\n",
    "\n",
    "    # subscribe\n",
    "    fe_sub = subscribe!(score(eltype(params), BetheFreeEnergy(), model), fe)\n",
    "\n",
    "    # update y and x according to observations (i.e. perform inference)\n",
    "    for k=1:nr_its\n",
    "        ReactiveMP.update!(y, data_y)\n",
    "        ReactiveMP.update!(x, data_x)\n",
    "    end\n",
    "\n",
    "    # unsubscribe\n",
    "    unsubscribe!(fe_sub)\n",
    "    \n",
    "    # return the marginal values\n",
    "    return getvalues(fe)[end]\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculate_parameters (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calculate_parameters(params, model, data_x, data_y)\n",
    "\n",
    "    function f(params)\n",
    "        fe = inference_flow_classifier(data_y, data_x, model, params)\n",
    "        return fe\n",
    "    end\n",
    "\n",
    "    optimizer = Adam(params; λ=1e-1)\n",
    "\n",
    "    ∇ = zeros(nr_params(model))\n",
    "\n",
    "    for it = 1:10000\n",
    "\n",
    "        # backward pass\n",
    "        ForwardDiff.gradient!(∇, f, optimizer.x)\n",
    "\n",
    "        # gradient update\n",
    "        ReactiveMP.update!(optimizer, ∇)\n",
    "\n",
    "    end\n",
    "\n",
    "    return f(optimizer.x), optimizer.x\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repeat_calculate_parameters (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function repeat_calculate_parameters(model, data_x, data_y)\n",
    "    try\n",
    "        x = calculate_parameters(randn(nr_params(model)), model, data_x, data_y)\n",
    "        @assert !isnan(x[1])\n",
    "        return x\n",
    "    catch e \n",
    "        println(e)\n",
    "        return repeat_calculate_parameters(model, data_x, data_y)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculate_parameters_tries (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calculate_parameters_tries(model, data_x, data_y; nr_tries=1)\n",
    "    params = Vector{Vector{Float64}}(undef, nr_tries)\n",
    "    fe = Vector{Float64}(undef, nr_tries)\n",
    "    Threads.@threads for k = 1:nr_tries\n",
    "        fe[k], params[k] = repeat_calculate_parameters(model, data_x, data_y)\n",
    "    end\n",
    "    println(fe)\n",
    "    return params[argmin(fe)]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference input estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct PointMassFormConstraint2{P}\n",
    "    point :: P   \n",
    "end\n",
    "\n",
    "ReactiveMP.default_form_check_strategy(::PointMassFormConstraint2) = FormConstraintCheckLast()\n",
    "\n",
    "ReactiveMP.is_point_mass_form_constraint(::PointMassFormConstraint2) = true\n",
    "\n",
    "function ReactiveMP.constrain_form(pmconstraint::PointMassFormConstraint2, message::Message) \n",
    "    is_clamped = ReactiveMP.is_clamped(message)\n",
    "    is_initial = ReactiveMP.is_initial(message)\n",
    "    return Message(PointMass(pmconstraint.point), is_clamped, is_initial)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function flow_classifier_input(input, model, params)\n",
    "    \n",
    "    # initialize variables\n",
    "    x_lat  = randomvar()\n",
    "    y_lat1 = randomvar()\n",
    "    y_lat2 = randomvar()\n",
    "    xprior = randomvar() where { form_constraint = PointMassFormConstraint2(input)}\n",
    "    y = datavar(Float64)\n",
    "\n",
    "    # specify model\n",
    "    meta  = FlowMeta(compile(model, params))\n",
    "\n",
    "    # specify prior on weights\n",
    "    xprior ~ MvNormalMeanPrecision([0.0,0.0], 0.1*diagm(ones(2))) where { q = MeanField() }\n",
    "\n",
    "    # specify latent state\n",
    "    x_lat ~ MvNormalMeanPrecision(xprior, 1e3*diagm(ones(2))) where { q = MeanField() }\n",
    "\n",
    "    # specify transformed latent value\n",
    "    y_lat1 ~ Flow(x_lat) where { meta = meta }\n",
    "    y_lat2 ~ dot(y_lat1, [1, 1])\n",
    "\n",
    "    # specify observations\n",
    "    y ~ Probit(y_lat2) # default where { pipeline = RequireInbound(in = NormalMeanPrecision(0, 1.0)) }\n",
    "\n",
    "    # return variables\n",
    "    return x_lat, y_lat1, y_lat2, y\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "function inference_flow_classifier_input(input, flow_model, params; nr_its=5)\n",
    "\n",
    "    # define model\n",
    "    model, (x_lat, y_lat1, y_lat2, y) = flow_classifier_input(input, flow_model, params)\n",
    "\n",
    "    # initialize free energy\n",
    "    fe = ScoreActor(eltype(input))\n",
    "    \n",
    "    # subscribe\n",
    "    fe_sub = subscribe!(score(eltype(input), BetheFreeEnergy(), model), fe)\n",
    "\n",
    "    setmarginal!(x_lat, vague(MvNormalMeanPrecision, 2))\n",
    "    \n",
    "    # update y and x according to observations (i.e. perform inference)\n",
    "    for k = 1:nr_its\n",
    "        ReactiveMP.update!(y, 1.0)\n",
    "    end\n",
    "\n",
    "    # unsubscribe\n",
    "    unsubscribe!(fe_sub)\n",
    "    \n",
    "    # return the marginal values\n",
    "    return getvalues(fe)[end]\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculate_input (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calculate_input(params, model)\n",
    "\n",
    "    function f_input(input)\n",
    "        fe = inference_flow_classifier_input(input, model, params)\n",
    "        return fe\n",
    "    end\n",
    "\n",
    "    optimizer = Adam(randn(2); λ=1e-1)\n",
    "\n",
    "    ∇ = zeros(2)\n",
    "\n",
    "    for it = 1:10000\n",
    "\n",
    "        # backward pass\n",
    "        ForwardDiff.gradient!(∇, f_input, optimizer.x)\n",
    "\n",
    "        # gradient update\n",
    "        ReactiveMP.update!(optimizer, ∇)\n",
    "\n",
    "    end\n",
    "\n",
    "    return f_input(optimizer.x), optimizer.x\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repeat_calculate_input (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function repeat_calculate_input(params, model)\n",
    "    try\n",
    "        return calculate_input(params, model)\n",
    "    catch e\n",
    "        # println(\"   ERROR: calculate_input() failed\")\n",
    "        println(e)\n",
    "        return repeat_calculate_input(params, model)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculate_input_tries (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calculate_input_tries(params, model; nr_tries=1)\n",
    "    input = Vector{Vector{Float64}}(undef, nr_tries)\n",
    "    fe = Vector{Float64}(undef, nr_tries)\n",
    "    Threads.@threads for k = 1:nr_tries\n",
    "        fe[k], input[k] = repeat_calculate_input(params, model)\n",
    "    end\n",
    "    return input[argmin(fe)]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot_figure (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function plot_figure(model, data_x, data_y, it)\n",
    "    classification_map = map((x) -> normcdf(dot([1,1],x)), map((x) -> forward(model, norminvcdf.([x...])), collect(Iterators.product(0.0:0.01:1.0, 0.0:0.01:1.0))))\n",
    "    fig, ax = plt.subplots(ncols = 1)\n",
    "    im = ax.contourf(repeat(0:0.01:1, 1, 101), repeat(0:0.01:1, 1, 101)', classification_map)\n",
    "    ax.scatter(normcdf.(hcat(data_x...)[1,:]), normcdf.(hcat(data_x...)[2,:]), c=\"white\")\n",
    "    ax.scatter(normcdf.(hcat(data_x...)[1,:]), normcdf.(hcat(data_x...)[2,:]), c=data_y, marker=\"x\", vmin=0, vmax=1)\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(\"gain 1\"), ax.set_ylabel(\"gain 2\")\n",
    "    ax.set_title(string(\"Iteration \", it));\n",
    "    plt.savefig(string(\"exports/NF_preferences_continuous_probit_\", it, \".eps\"))\n",
    "    plt.savefig(string(\"exports/NF_preferences_continuous_probit_\", it, \".png\"))\n",
    "    plt.close(\"all\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User preference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learn_user_preferences (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function learn_user_preferences(model; jitter=1, μ=[0.8, 0.2], a=1, b=1, c=25, d=-0.4, nr_tries_params=1, nr_tries_input=1, nr_its=20)\n",
    "\n",
    "    # set flags\n",
    "    DONE = false\n",
    "    it = 1\n",
    "\n",
    "    # select random data point (initial)\n",
    "    optimum = rand(2)\n",
    "    r = generate_user_response(optimum; μ=μ, a=a, b=b, c=c, d=d, binary=false)\n",
    "    data_y = [r*ones(jitter)...]\n",
    "    data_x = [[norminvcdf.(optimum + randn(2)*0.01) for k=1:jitter]...]\n",
    "    optimum = rand(2)\n",
    "    r = generate_user_response(optimum; μ=μ, a=a, b=b, c=c, d=d, binary=false)\n",
    "    data_y = [data_y..., r*ones(jitter)...]\n",
    "    data_x = [data_x..., [norminvcdf.(optimum + randn(2)*0.01) for k=1:jitter]...]\n",
    "\n",
    "    # preference learning loop\n",
    "    while DONE == false && it <= nr_its\n",
    "\n",
    "        # calculate parameters\n",
    "        params = calculate_parameters_tries(flow_model, data_x, data_y; nr_tries=nr_tries_params)\n",
    "        inferred_model = compile(flow_model, params)\n",
    "\n",
    "        # create plot\n",
    "        plot_figure(inferred_model, data_x, data_y, it)\n",
    "\n",
    "        # propose preferences\n",
    "        optimum = calculate_input_tries(params, flow_model; nr_tries=nr_tries_input)\n",
    "\n",
    "        # updata data\n",
    "        r = generate_user_response(normcdf.(optimum); μ=μ, a=a, b=b, c=c, d=d, binary=false)\n",
    "        data_y = [data_y..., r*ones(jitter)...]\n",
    "        data_x = [data_x..., [optimum + randn(2)*0.01 for k=1:jitter]...]\n",
    "\n",
    "        # print summary\n",
    "        println(string(\"Iteration \", it, \":\"))\n",
    "        println(string(\"    proposal: \", normcdf.(optimum)))\n",
    "        println(string(\"    response: \", r))\n",
    "\n",
    "        # check if done\n",
    "        if r == 1\n",
    "            DONE = true\n",
    "        end\n",
    "\n",
    "        # update iteration number\n",
    "        it += 1\n",
    "\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6786748221760135, 0.6787526643798785, 0.6835925258436468]\n",
      "Iteration 1:\n",
      "    proposal: [0.7879371303135341, 0.5161124662919936]\n",
      "    response: 0.007105531757471016\n",
      "[0.7260827597416437, 0.7268080780415573, 0.722359722671122]\n",
      "Iteration 2:\n",
      "    proposal: [0.374075922925891, 0.9666345701691247]\n",
      "    response: 1.3434349933584359e-8\n",
      "[0.7269387946097012, 0.7265292154718921, 0.7292836518001238]\n",
      "Iteration 3:\n",
      "    proposal: [0.9333463660054253, 0.020297223335056513]\n",
      "    response: 0.059373534688748196\n",
      "[1.5278188521497142, 0.9584897576097191, 0.9590028770605485]\n",
      "Iteration 4:\n",
      "    proposal: [0.9293207892485258, 0.6695699168521686]\n",
      "    response: 0.00012913765666427564\n",
      "[0.9872957087420602, 0.9851429370513998, 1.063314796869598]\n",
      "Iteration 5:\n",
      "    proposal: [0.9861992276865091, 0.3363280034345767]\n",
      "    response: 0.05082095279619482\n",
      "[1.299927803157587, 1.274581518323373, 1.3261913414725512]\n",
      "Iteration 6:\n",
      "    proposal: [0.9946897601222666, 0.9890829041819825]\n",
      "    response: 6.089125435415273e-8\n",
      "[1.4767447885179905, 15.033453876375631, 15.032854587369528]\n",
      "Iteration 7:\n",
      "    proposal: [0.9835029795395698, 0.10919518567873454]\n",
      "    response: 0.0898799047786224\n",
      "[2.394347551238951, 2.283547580545772, 2.2687968731749777]\n",
      "Iteration 8:\n",
      "    proposal: [0.9970658416489615, 0.01952073184535843]\n",
      "    response: 0.02221465723546719\n",
      "[3.037154976087436, 2.931090882562799, 2.813797679004466]\n",
      "Iteration 9:\n",
      "    proposal: [0.9961422731804248, 0.002725201246345925]\n",
      "    response: 0.017251473665270765\n",
      "[16.224926938747046, 3.1619224162481743, 3.0807916373326236]\n"
     ]
    }
   ],
   "source": [
    "learn_user_preferences(flow_model; nr_tries_params=3, nr_tries_input=3, nr_its=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20-23s (compiled)\n",
    "# 16s (threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, ax = plt.subplots(ncols=1)\n",
    "# classification_map = map((x) -> generate_user_response([x...]; μ=[0.8, 0.2], binary=false), collect(Iterators.product(0:0.01:1, 0:0.01:1)))\n",
    "# im = ax.contourf(repeat(0:0.01:1, 1, 101), repeat(0:0.01:1, 1, 101)', classification_map)\n",
    "# plt.colorbar(im, ax=ax)\n",
    "# ax.grid()\n",
    "# ax.set_xlabel(\"gain 1\"), ax.set_ylabel(\"gain 2\")\n",
    "# ax.set_title(\"Actual user response\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = randn(nr_params(flow_model))\n",
    "# optimum = rand(2)\n",
    "# jitter = 1\n",
    "# r = generate_user_response(optimum; binary=false)\n",
    "# data_y = [r*ones(jitter)...]\n",
    "# data_x = [[optimum + randn(2)*0.01 for k=1:jitter]...]\n",
    "# optimum = rand(2)\n",
    "# r = generate_user_response(optimum; binary=false)\n",
    "# data_y = [data_y..., r*ones(jitter)...]\n",
    "# data_x = [data_x..., [optimum + randn(2)*0.01 for k=1:jitter]...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_parameters(params, flow_model, data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @code_warntype calculate_parameters(params, flow_model, data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @benchmark calculate_parameters($params, $flow_model, $data_x, $data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_parameters(params, flow_model, data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Profile\n",
    "\n",
    "# @profile calculate_parameters(params, flow_model, data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # type stable\n",
    "# BenchmarkTools.Trial: \n",
    "#   memory estimate:  243.89 MiB\n",
    "#   allocs estimate:  3022996\n",
    "#   --------------\n",
    "#   minimum time:     623.854 ms (4.87% GC)\n",
    "#   median time:      644.346 ms (4.91% GC)\n",
    "#   mean time:        656.192 ms (4.89% GC)\n",
    "#   maximum time:     713.424 ms (4.75% GC)\n",
    "#   --------------\n",
    "#   samples:          8\n",
    "#   evals/sample:     1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initial\n",
    "# BenchmarkTools.Trial: \n",
    "#   memory estimate:  244.15 MiB\n",
    "#   allocs estimate:  3035514\n",
    "#   --------------\n",
    "#   minimum time:     751.122 ms (4.73% GC)\n",
    "#   median time:      825.649 ms (4.95% GC)\n",
    "#   mean time:        849.803 ms (4.95% GC)\n",
    "#   maximum time:     1.027 s (4.25% GC)\n",
    "#   --------------\n",
    "#   samples:          7\n",
    "#   evals/sample:     1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
