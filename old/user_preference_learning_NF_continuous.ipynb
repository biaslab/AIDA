{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User preference learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "\n",
    "using ReactiveMP\n",
    "using Rocket\n",
    "using GraphPPL\n",
    "\n",
    "using Optim\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using PyPlot\n",
    "using StatsFuns: normcdf\n",
    "\n",
    "\n",
    "include(\"../src/environment/user.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify flow model\n",
    "flow_model = FlowModel(2,\n",
    "    (\n",
    "        AdditiveCouplingLayer(PlanarFlow()), # defaults to AdditiveCouplingLayer(PlanarFlow(); permute=true)\n",
    "        AdditiveCouplingLayer(PlanarFlow()),\n",
    "        AdditiveCouplingLayer(PlanarFlow(); permute=false)\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function flow_classifier(nr_samples::Int64, model::FlowModel, params)\n",
    "    \n",
    "    # initialize variables\n",
    "    x_lat  = randomvar(nr_samples)\n",
    "    y_lat1 = randomvar(nr_samples)\n",
    "    y_lat2 = randomvar(nr_samples)\n",
    "    y      = datavar(Float64, nr_samples)\n",
    "    x      = datavar(Vector{Float64}, nr_samples)\n",
    "\n",
    "    # compile flow model\n",
    "    meta  = FlowMeta(compile(model, params)) # default: FlowMeta(model, Linearization())\n",
    "\n",
    "    # specify observations\n",
    "    for k = 1:nr_samples\n",
    "\n",
    "        # specify latent state\n",
    "        x_lat[k] ~ MvNormalMeanPrecision(x[k], 1e3*diagm(ones(2)))\n",
    "\n",
    "\n",
    "        # specify transformed latent value\n",
    "        y_lat1[k] ~ Flow(x_lat[k]) where { meta = meta }\n",
    "        y_lat2[k] ~ dot(y_lat1[k], [1, 1])\n",
    "\n",
    "        # specify observations\n",
    "        y[k] ~ Probit(y_lat2[k]) # default: where { pipeline = RequireInbound(in = NormalMeanPrecision(0, 1.0)) }\n",
    "\n",
    "    end\n",
    "\n",
    "    # return variables\n",
    "    return x_lat, x, y_lat1, y_lat2, y\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function inference_flow_classifier(data_y::Array{Float64,1}, data_x::Array{Array{Float64,1},1}, model::FlowModel, params)\n",
    "    \n",
    "    # fetch number of samples\n",
    "    nr_samples = length(data_y)\n",
    "\n",
    "    # define model\n",
    "    model, (x_lat, x, y_lat1, y_lat2, y) = flow_classifier(nr_samples, model, params)\n",
    "\n",
    "    # initialize free energy\n",
    "    fe_buffer = nothing\n",
    "    \n",
    "    # subscribe\n",
    "    fe_sub = subscribe!(score(BetheFreeEnergy(), model), (fe) -> fe_buffer = fe)\n",
    "\n",
    "    # update y and x according to observations (i.e. perform inference)\n",
    "    ReactiveMP.update!(y, data_y)\n",
    "    ReactiveMP.update!(x, data_x)\n",
    "\n",
    "    # unsubscribe\n",
    "    unsubscribe!(fe_sub)\n",
    "    \n",
    "    # return the marginal values\n",
    "    return fe_buffer\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function calculate_parameters(params, model, data_x, data_y)\n",
    "\n",
    "    function f(params)\n",
    "        fe = inference_flow_classifier(data_y, data_x, model, params)\n",
    "        return fe\n",
    "    end\n",
    "\n",
    "    res = optimize(f, params, LBFGS(), Optim.Options(iterations = 500, store_trace = false, show_trace = false), autodiff=:forward)\n",
    "\n",
    "    return Optim.minimum(res), Optim.minimizer(res)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function repeat_calculate_parameters(model, data_x, data_y)\n",
    "    try\n",
    "        return calculate_parameters(randn(nr_params(model)), model, data_x, data_y)\n",
    "    catch\n",
    "        println(\"   ERROR: calculate_parameters() failed\")\n",
    "        return repeat_calculate_parameters(model, data_x, data_y)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function calculate_parameters_tries(model, data_x, data_y; nr_tries=1)\n",
    "    params = []\n",
    "    fe = []\n",
    "    Threads.@threads for k = 1:nr_tries\n",
    "        fe_tmp, params_tmp = repeat_calculate_parameters(model, data_x, data_y)\n",
    "        push!(params, params_tmp)\n",
    "        push!(fe, fe_tmp)\n",
    "    end\n",
    "    return params[argmin(fe)]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference input estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct PointMassFormConstraint2{P}\n",
    "    point :: P   \n",
    "end\n",
    "\n",
    "ReactiveMP.default_form_check_strategy(::PointMassFormConstraint2) = FormConstraintCheckLast()\n",
    "\n",
    "ReactiveMP.is_point_mass_form_constraint(::PointMassFormConstraint2) = true\n",
    "\n",
    "function ReactiveMP.constrain_form(pmconstraint::PointMassFormConstraint2, message::Message) \n",
    "    is_clamped = ReactiveMP.is_clamped(message)\n",
    "    is_initial = ReactiveMP.is_initial(message)\n",
    "    return Message(PointMass(pmconstraint.point), is_clamped, is_initial)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function flow_classifier_input(input, model, params)\n",
    "    \n",
    "    # initialize variables\n",
    "    x_lat  = randomvar()\n",
    "    y_lat1 = randomvar()\n",
    "    y_lat2 = randomvar()\n",
    "    xprior = randomvar() where { form_constraint = PointMassFormConstraint2(input)}\n",
    "    y = datavar(Float64)\n",
    "\n",
    "    # specify model\n",
    "    meta  = FlowMeta(compile(model, params))\n",
    "\n",
    "    # specify prior on weights\n",
    "    xprior ~ MvNormalMeanPrecision([0.5,0.5], 0.1*diagm(ones(2))) where { q = MeanField() }\n",
    "\n",
    "    # specify latent state\n",
    "    x_lat ~ MvNormalMeanPrecision(xprior, 1e3*diagm(ones(2))) where { q = MeanField() }\n",
    "\n",
    "    # specify transformed latent value\n",
    "    y_lat1 ~ Flow(x_lat) where { meta = meta }\n",
    "    y_lat2 ~ dot(y_lat1, [1, 1])\n",
    "\n",
    "    # specify observations\n",
    "    y ~ Probit(y_lat2) # default where { pipeline = RequireInbound(in = NormalMeanPrecision(0, 1.0)) }\n",
    "\n",
    "    # return variables\n",
    "    return x_lat, y_lat1, y_lat2, y\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function inference_flow_classifier_input(input, model, params)\n",
    "\n",
    "    # define model\n",
    "    model, (x_lat, y_lat1, y_lat2, y) = flow_classifier_input(input, model, params)\n",
    "\n",
    "    # initialize free energy\n",
    "    fe_buffer = nothing\n",
    "    \n",
    "    # subscribe\n",
    "    fe_sub = subscribe!(score(eltype(input), BetheFreeEnergy(), model), (fe) -> fe_buffer = fe)\n",
    "\n",
    "    setmarginal!(x_lat, vague(MvNormalMeanPrecision, 2))\n",
    "    \n",
    "    # update y and x according to observations (i.e. perform inference)\n",
    "    for k = 1:10\n",
    "        ReactiveMP.update!(y, 1.0)\n",
    "    end\n",
    "\n",
    "    # unsubscribe\n",
    "    unsubscribe!(fe_sub)\n",
    "    \n",
    "    # return the marginal values\n",
    "    return fe_buffer\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function calculate_input(params, model)\n",
    "\n",
    "    function f_input(input)\n",
    "        fe = inference_flow_classifier_input(input, model, params)\n",
    "        return fe\n",
    "    end\n",
    "\n",
    "    res = optimize(f_input, zeros(2), ones(2), rand(2), Fminbox(LBFGS()), Optim.Options(iterations = 500, store_trace = false, show_trace = false), autodiff=:forward)\n",
    "\n",
    "    return Optim.minimum(res), Optim.minimizer(res)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function repeat_calculate_input(params, model)\n",
    "    try\n",
    "        return calculate_input(params, model)\n",
    "    catch\n",
    "        println(\"   ERROR: calculate_input() failed\")\n",
    "        return repeat_calculate_input(params, model)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function calculate_input_tries(params, model; nr_tries=1)\n",
    "    input = []\n",
    "    fe = []\n",
    "    Threads.@threads for k = 1:nr_tries\n",
    "        fe_tmp, input_tmp = repeat_calculate_input(params, model)\n",
    "        push!(input, input_tmp)\n",
    "        push!(fe, fe_tmp)\n",
    "    end\n",
    "    return input[argmin(fe)]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function plot_figure(model, data_x, data_y, it)\n",
    "    classification_map = map((x) -> normcdf(dot([1,1],x)), map((x) -> forward(model, [x...]), collect(Iterators.product(0:0.01:1, 0:0.01:1))))\n",
    "    fig, ax = plt.subplots(ncols = 1)\n",
    "    im = ax.contourf(repeat(0:0.01:1, 1, 101), repeat(0:0.01:1, 1, 101)', classification_map)\n",
    "    ax.scatter(hcat(data_x...)[1,:], hcat(data_x...)[2,:], c=data_y, marker=\"x\")\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(\"gain 1\"), ax.set_ylabel(\"gain 2\")\n",
    "    ax.set_title(string(\"Call \", it));\n",
    "    plt.savefig(string(\"exports/NF_preferences_continuous_\", it, \".eps\"))\n",
    "    plt.savefig(string(\"exports/NF_preferences_continuous_\", it, \".png\"))\n",
    "    plt.close(\"all\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User preference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function learn_user_preferences(model; jitter=1, μ=[0.8, 0.2], a=1, b=1, c=25, d=-0.4, nr_tries=1, nr_its=20)\n",
    "\n",
    "    # set flags\n",
    "    DONE = false\n",
    "    it = 1\n",
    "\n",
    "    # select random data point (initial)\n",
    "    optimum = rand(2)\n",
    "    r = generate_user_response(optimum; μ=μ, a=a, b=b, c=c, d=d, binary=false)\n",
    "    data_y = [r*ones(jitter)...]\n",
    "    data_x = [[optimum + randn(2)*0.01 for k=1:jitter]...]\n",
    "    optimum = rand(2)\n",
    "    r = generate_user_response(optimum; μ=μ, a=a, b=b, c=c, d=d, binary=false)\n",
    "    data_y = [data_y..., r*ones(jitter)...]\n",
    "    data_x = [data_x..., [optimum + randn(2)*0.01 for k=1:jitter]...]\n",
    "\n",
    "    # preference learning loop\n",
    "    while DONE == false && it <= nr_its\n",
    "\n",
    "        # calculate parameters\n",
    "        params = calculate_parameters_tries(flow_model, data_x, data_y; nr_tries=nr_tries)\n",
    "        inferred_model = compile(flow_model, params)\n",
    "\n",
    "        # create plot\n",
    "        plot_figure(inferred_model, data_x, data_y, it)\n",
    "\n",
    "        # propose preferences\n",
    "        optimum = calculate_input_tries(params, flow_model; nr_tries=nr_tries)\n",
    "\n",
    "        # updata data\n",
    "        r = generate_user_response(optimum; μ=μ, a=a, b=b, c=c, d=d, binary=false)\n",
    "        data_y = [data_y..., r*ones(jitter)...]\n",
    "        data_x = [data_x..., [optimum + randn(2)*0.01 for k=1:jitter]...]\n",
    "\n",
    "        # print summary\n",
    "        println(string(\"Iteration \", it, \":\"))\n",
    "        println(string(\"    proposal: \", optimum))\n",
    "        println(string(\"    response: \", r))\n",
    "\n",
    "        # check if done\n",
    "        if r == 1\n",
    "            DONE = true\n",
    "        end\n",
    "\n",
    "        # update iteration number\n",
    "        it += 1\n",
    "\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_user_preferences(flow_model; nr_tries=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(ncols=1)\n",
    "classification_map = map((x) -> generate_user_response([x...]; μ=[0.8, 0.2], binary=false), collect(Iterators.product(0:0.01:1, 0:0.01:1)))\n",
    "im = ax.contourf(repeat(0:0.01:1, 1, 101), repeat(0:0.01:1, 1, 101)', classification_map)\n",
    "plt.colorbar(im, ax=ax)\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"gain 1\"), ax.set_ylabel(\"gain 2\")\n",
    "ax.set_title(\"Actual user response\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
