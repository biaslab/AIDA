{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User preference learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "\n",
    "using ReactiveMP\n",
    "using Rocket\n",
    "using GraphPPL\n",
    "\n",
    "using Optim\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using PyPlot\n",
    "using StatsFuns: normcdf\n",
    "using ForwardDiff\n",
    "using BenchmarkTools\n",
    "\n",
    "\n",
    "include(\"../src/environment/user.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify flow model\n",
    "flow_model = FlowModel(2,\n",
    "    (\n",
    "        AdditiveCouplingLayer(RadialFlow()), # defaults to AdditiveCouplingLayer(PlanarFlow(); permute=true)\n",
    "        AdditiveCouplingLayer(RadialFlow()),\n",
    "        AdditiveCouplingLayer(RadialFlow(); permute=false)\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function flow_classifier(nr_samples::Int64, model::FlowModel, params)\n",
    "    \n",
    "    # initialize variables\n",
    "    x_lat  = randomvar(nr_samples)\n",
    "    y_lat1 = randomvar(nr_samples)\n",
    "    y_lat2 = randomvar(nr_samples)\n",
    "    y      = datavar(Float64, nr_samples)\n",
    "    x      = datavar(Vector{Float64}, nr_samples)\n",
    "\n",
    "    # compile flow model\n",
    "    meta  = FlowMeta(compile(model, params)) # default: FlowMeta(model, Linearization())\n",
    "\n",
    "    # specify observations\n",
    "    for k = 1:nr_samples\n",
    "\n",
    "        # specify latent state\n",
    "        x_lat[k] ~ MvNormalMeanPrecision(x[k], 1e3*diagm(ones(2)))\n",
    "\n",
    "        # specify transformed latent value\n",
    "        y_lat1[k] ~ Flow(x_lat[k]) where { meta = meta }\n",
    "        y_lat2[k] ~ dot(y_lat1[k], [1, 1])\n",
    "\n",
    "        # specify observations\n",
    "        y[k] ~ Probit(y_lat2[k]) # default: where { pipeline = RequireInbound(in = NormalMeanPrecision(0, 1.0)) }\n",
    "\n",
    "    end\n",
    "\n",
    "    # return variables\n",
    "    return x, y\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function inference_flow_classifier(data_y::Array{Float64,1}, data_x::Array{Array{Float64,1},1}, flow_model::FlowModel, params; nr_its=5)\n",
    "    \n",
    "    # fetch number of samples\n",
    "    nr_samples = length(data_y)\n",
    "\n",
    "    # define model\n",
    "    model, (x, y) = flow_classifier(nr_samples, flow_model, params)\n",
    "\n",
    "    # initialize free energy\n",
    "    fe = ScoreActor(eltype(params))\n",
    "\n",
    "    # subscribe\n",
    "    fe_sub = subscribe!(score(eltype(params), BetheFreeEnergy(), model), fe)\n",
    "\n",
    "    # update y and x according to observations (i.e. perform inference)\n",
    "    for k=1:nr_its\n",
    "        ReactiveMP.update!(y, data_y)\n",
    "        ReactiveMP.update!(x, data_x)\n",
    "    end\n",
    "\n",
    "    # unsubscribe\n",
    "    unsubscribe!(fe_sub)\n",
    "    \n",
    "    # return the marginal values\n",
    "    return getvalues(fe)[end]\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculate_parameters (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calculate_parameters(params, model, data_x, data_y)\n",
    "\n",
    "    function f(params)\n",
    "        fe = inference_flow_classifier(data_y, data_x, model, params)\n",
    "        return fe\n",
    "    end\n",
    "\n",
    "    optimizer = Adam(params; λ=1e-1)\n",
    "\n",
    "    ∇ = zeros(nr_params(model))\n",
    "\n",
    "    for it = 1:10000\n",
    "\n",
    "        # backward pass\n",
    "        ForwardDiff.gradient!(∇, f, optimizer.x)\n",
    "\n",
    "        # gradient update\n",
    "        ReactiveMP.update!(optimizer, ∇)\n",
    "\n",
    "    end\n",
    "\n",
    "    return f(optimizer.x), optimizer.x\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function repeat_calculate_parameters(model, data_x, data_y)\n",
    "#     try\n",
    "#         return calculate_parameters(randn(nr_params(model)), model, data_x, data_y)\n",
    "#     catch e\n",
    "#         #println(\"   ERROR: calculate_parameters() failed\")\n",
    "#         #return repeat_calculate_parameters(model, data_x, data_y)\n",
    "#         println(e)\n",
    "#     end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculate_parameters_tries (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calculate_parameters_tries(model, data_x, data_y; nr_tries=1)\n",
    "    params = Vector{Vector{Float64}}(undef, nr_tries)\n",
    "    fe = Vector{Float64}(undef, nr_tries)\n",
    "    Threads.@threads for k = 1:nr_tries\n",
    "        fe[k], params[k] = calculate_parameters(randn(nr_params(model)), model, data_x, data_y)\n",
    "    end\n",
    "    println(fe)\n",
    "    return params[argmin(fe)]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference input estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct PointMassFormConstraint2{P}\n",
    "    point :: P   \n",
    "end\n",
    "\n",
    "ReactiveMP.default_form_check_strategy(::PointMassFormConstraint2) = FormConstraintCheckLast()\n",
    "\n",
    "ReactiveMP.is_point_mass_form_constraint(::PointMassFormConstraint2) = true\n",
    "\n",
    "function ReactiveMP.constrain_form(pmconstraint::PointMassFormConstraint2, message::Message) \n",
    "    is_clamped = ReactiveMP.is_clamped(message)\n",
    "    is_initial = ReactiveMP.is_initial(message)\n",
    "    return Message(PointMass(pmconstraint.point), is_clamped, is_initial)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function flow_classifier_input(input, model, params)\n",
    "    \n",
    "    # initialize variables\n",
    "    x_lat  = randomvar()\n",
    "    y_lat1 = randomvar()\n",
    "    y_lat2 = randomvar()\n",
    "    xprior = randomvar() where { form_constraint = PointMassFormConstraint2(input)}\n",
    "    y = datavar(Float64)\n",
    "\n",
    "    # specify model\n",
    "    meta  = FlowMeta(compile(model, params))\n",
    "\n",
    "    # specify prior on weights\n",
    "    xprior ~ MvNormalMeanPrecision([0.0,0.0], 0.1*diagm(ones(2))) where { q = MeanField() }\n",
    "\n",
    "    # specify latent state\n",
    "    x_lat ~ MvNormalMeanPrecision(xprior, 1e3*diagm(ones(2))) where { q = MeanField() }\n",
    "\n",
    "    # specify transformed latent value\n",
    "    y_lat1 ~ Flow(x_lat) where { meta = meta }\n",
    "    y_lat2 ~ dot(y_lat1, [1, 1])\n",
    "\n",
    "    # specify observations\n",
    "    y ~ Probit(y_lat2) # default where { pipeline = RequireInbound(in = NormalMeanPrecision(0, 1.0)) }\n",
    "\n",
    "    # return variables\n",
    "    return x_lat, y_lat1, y_lat2, y\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "function inference_flow_classifier_input(input, flow_model, params; nr_its=5)\n",
    "\n",
    "    # define model\n",
    "    model, (x_lat, y_lat1, y_lat2, y) = flow_classifier_input(input, flow_model, params)\n",
    "\n",
    "    # initialize free energy\n",
    "    fe = ScoreActor(eltype(input))\n",
    "    \n",
    "    # subscribe\n",
    "    fe_sub = subscribe!(score(eltype(input), BetheFreeEnergy(), model), fe)\n",
    "\n",
    "    setmarginal!(x_lat, vague(MvNormalMeanPrecision, 2))\n",
    "    \n",
    "    # update y and x according to observations (i.e. perform inference)\n",
    "    for k = 1:nr_its\n",
    "        ReactiveMP.update!(y, 1.0)\n",
    "    end\n",
    "\n",
    "    # unsubscribe\n",
    "    unsubscribe!(fe_sub)\n",
    "    \n",
    "    # return the marginal values\n",
    "    return getvalues(fe)[end]\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculate_input (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calculate_input(params, model)\n",
    "\n",
    "    function f_input(input)\n",
    "        fe = inference_flow_classifier_input(input, model, params)\n",
    "        return fe\n",
    "    end\n",
    "\n",
    "    res = optimize(f_input, -0.5.*ones(2), 0.5.*ones(2), rand(2).-0.5, Fminbox(LBFGS()), Optim.Options(iterations = 500, store_trace = false, show_trace = false), autodiff=:forward)\n",
    "\n",
    "    return Optim.minimum(res), Optim.minimizer(res)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repeat_calculate_input (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function repeat_calculate_input(params, model)\n",
    "    try\n",
    "        return calculate_input(params, model)\n",
    "    catch \n",
    "        # println(\"   ERROR: calculate_input() failed\")\n",
    "        return repeat_calculate_input(params, model)\n",
    "        # println(e)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculate_input_tries (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calculate_input_tries(params, model; nr_tries=1)\n",
    "    input = Vector{Vector{Float64}}(undef, nr_tries)\n",
    "    fe = Vector{Float64}(undef, nr_tries)\n",
    "    Threads.@threads for k = 1:nr_tries\n",
    "        fe[k], input[k] = repeat_calculate_input(params, model)\n",
    "    end\n",
    "    return input[argmin(fe)]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot_figure (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function plot_figure(model, data_x, data_y, it)\n",
    "    classification_map = map((x) -> normcdf(dot([1,1],x)), map((x) -> forward(model, [x...]), collect(Iterators.product(-0.5:0.01:0.5, -0.5:0.01:0.5))))\n",
    "    fig, ax = plt.subplots(ncols = 1)\n",
    "    im = ax.contourf(repeat(0:0.01:1, 1, 101), repeat(0:0.01:1, 1, 101)', classification_map)\n",
    "    ax.scatter(hcat(data_x...)[1,:].+0.5, hcat(data_x...)[2,:].+0.5, c=\"white\")\n",
    "    ax.scatter(hcat(data_x...)[1,:].+0.5, hcat(data_x...)[2,:].+0.5, c=data_y, marker=\"x\", vmin=0, vmax=1)\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(\"gain 1\"), ax.set_ylabel(\"gain 2\")\n",
    "    ax.set_title(string(\"Iteration \", it));\n",
    "    plt.savefig(string(\"exports/NF_preferences_continuous_\", it, \".eps\"))\n",
    "    plt.savefig(string(\"exports/NF_preferences_continuous_\", it, \".png\"))\n",
    "    plt.close(\"all\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User preference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learn_user_preferences (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function learn_user_preferences(model; jitter=1, μ=[0.8, 0.2], a=1, b=1, c=25, d=-0.4, nr_tries_params=1, nr_tries_input=1, nr_its=20)\n",
    "\n",
    "    # set flags\n",
    "    DONE = false\n",
    "    it = 1\n",
    "\n",
    "    # select random data point (initial)\n",
    "    optimum = rand(2)\n",
    "    r = generate_user_response(optimum; μ=μ, a=a, b=b, c=c, d=d, binary=false)\n",
    "    data_y = [r*ones(jitter)...]\n",
    "    data_x = [[optimum.-0.5 + randn(2)*0.01 for k=1:jitter]...]\n",
    "    optimum = rand(2)\n",
    "    r = generate_user_response(optimum; μ=μ, a=a, b=b, c=c, d=d, binary=false)\n",
    "    data_y = [data_y..., r*ones(jitter)...]\n",
    "    data_x = [data_x..., [optimum.-0.5 + randn(2)*0.01 for k=1:jitter]...]\n",
    "\n",
    "    # preference learning loop\n",
    "    while DONE == false && it <= nr_its\n",
    "\n",
    "        # calculate parameters\n",
    "        params = calculate_parameters_tries(flow_model, data_x, data_y; nr_tries=nr_tries_params)\n",
    "        inferred_model = compile(flow_model, params)\n",
    "\n",
    "        # create plot\n",
    "        plot_figure(inferred_model, data_x, data_y, it)\n",
    "\n",
    "        # propose preferences\n",
    "        optimum = calculate_input_tries(params, flow_model; nr_tries=nr_tries_input)\n",
    "\n",
    "        # updata data\n",
    "        r = generate_user_response(optimum.+0.5; μ=μ, a=a, b=b, c=c, d=d, binary=false)\n",
    "        data_y = [data_y..., r*ones(jitter)...]\n",
    "        data_x = [data_x..., [optimum + randn(2)*0.01 for k=1:jitter]...]\n",
    "\n",
    "        # print summary\n",
    "        println(string(\"Iteration \", it, \":\"))\n",
    "        println(string(\"    proposal: \", optimum))\n",
    "        println(string(\"    response: \", r))\n",
    "\n",
    "        # check if done\n",
    "        if r == 1\n",
    "            DONE = true\n",
    "        end\n",
    "\n",
    "        # update iteration number\n",
    "        it += 1\n",
    "\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.017429278680207716, 0.017535393644127595, 0.017555696822892486]\n",
      "Iteration 1:\n",
      "    proposal: [0.499999998759431, 0.4999999978435874]\n",
      "    response: 4.605371001232599e-8\n",
      "[0.018173378644686267, 0.022467656486945486, 0.014434504535081771]\n",
      "Iteration 2:\n",
      "    proposal: [-0.23993509753942596, -0.49994579224357866]\n",
      "    response: 1.603191860826699e-5\n",
      "[-0.42045443474683, 0.02178659241348413, 0.03771044250232336]\n",
      "Iteration 3:\n",
      "    proposal: [0.4999999561962362, 0.49999967769152726]\n",
      "    response: 4.605405759545056e-8\n",
      "[0.12887668289231868, 0.01836449351364422, 0.018397960641564737]\n",
      "Iteration 4:\n",
      "    proposal: [0.49999937290057656, -0.2947892925942674]\n",
      "    response: 0.09928577711860842\n",
      "[0.8988123473613427, 0.36802850214213834, 0.35106952415829795]\n",
      "Iteration 5:\n",
      "    proposal: [0.31061591141214706, 0.49997571942632707]\n",
      "    response: 8.20856263221042e-8\n",
      "[0.3589840358117513, 0.37283945508360716, 0.3584722470594457]\n",
      "Iteration 6:\n",
      "    proposal: [0.49999999999999994, -0.02549285692530829]\n",
      "    response: 0.004120627006167552\n",
      "[0.21788867484160335, 0.3850389197665436, 0.40462372768884336]\n",
      "Iteration 7:\n",
      "    proposal: [0.161317847610669, 0.49999270656657546]\n",
      "    response: 6.207929044628316e-8\n",
      "[0.3468565449750116, 0.3949420458913835, 1.2141794604459193]\n",
      "Iteration 8:\n",
      "    proposal: [0.4999996300441732, -0.3972796628277101]\n",
      "    response: 0.06119838623888652\n",
      "[0.6362801961264211, 0.8162547630881534, 0.6253907252324069]\n",
      "Iteration 9:\n",
      "    proposal: [0.4999999997654355, -0.3855798759979578]\n",
      "    response: 0.06810784529490405\n",
      "[0.8781287273363745, 2.4131515915494504, 0.893198016894047]\n",
      "Iteration 10:\n",
      "    proposal: [0.4999999694268059, -0.43526475444729307]\n",
      "    response: 0.039988616302148214\n",
      "[1.0741813230213637, 1.062575393421966, 1.039864090892877]\n",
      "Iteration 11:\n",
      "    proposal: [0.4999996917553098, -0.21581321026410985]\n",
      "    response: 0.06892517364176194\n",
      "[1.4028259492771298, 1.3163713841069153, 1.341031151606316]\n",
      "Iteration 12:\n",
      "    proposal: [0.49999776691928377, -0.313978908631276]\n",
      "    response: 0.0984091444263168\n",
      "[1.7076847004516509, 1.643398660932334, 2.6291867782999816]\n",
      "Iteration 13:\n",
      "    proposal: [-0.091293181833274, 0.4999997809936885]\n",
      "    response: 9.765797321697635e-9\n",
      "[1.7239460605918708, 1.6662390633851913, 1.7580412568859458]\n",
      "Iteration 14:\n",
      "    proposal: [0.45971315080102876, -0.18526764823366737]\n",
      "    response: 0.10670453961623362\n",
      "[2.016479646436636, 1.7658136524281929, 2.04047307684786]\n",
      "Iteration 15:\n",
      "    proposal: [0.49999999961322106, 0.49999780599079785]\n",
      "    response: 4.605601294282109e-8\n",
      "[2.11451596706425, 2.093667170570228, 1.9767575548503942]\n"
     ]
    }
   ],
   "source": [
    "learn_user_preferences(flow_model; nr_tries_params=3, nr_tries_input=10, nr_its=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = randn(nr_params(flow_model))\n",
    "# optimum = rand(2)\n",
    "# jitter = 1\n",
    "# r = generate_user_response(optimum; binary=false)\n",
    "# data_y = [r*ones(jitter)...]\n",
    "# data_x = [[optimum + randn(2)*0.01 for k=1:jitter]...]\n",
    "# optimum = rand(2)\n",
    "# r = generate_user_response(optimum; binary=false)\n",
    "# data_y = [data_y..., r*ones(jitter)...]\n",
    "# data_x = [data_x..., [optimum + randn(2)*0.01 for k=1:jitter]...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20-23s (compiled)\n",
    "# 16s (threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, ax = plt.subplots(ncols=1)\n",
    "# classification_map = map((x) -> generate_user_response([x...]; μ=[0.8, 0.2], binary=false), collect(Iterators.product(0:0.01:1, 0:0.01:1)))\n",
    "# im = ax.contourf(repeat(0:0.01:1, 1, 101), repeat(0:0.01:1, 1, 101)', classification_map)\n",
    "# plt.colorbar(im, ax=ax)\n",
    "# ax.grid()\n",
    "# ax.set_xlabel(\"gain 1\"), ax.set_ylabel(\"gain 2\")\n",
    "# ax.set_title(\"Actual user response\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = randn(nr_params(flow_model))\n",
    "# optimum = rand(2)\n",
    "# jitter = 1\n",
    "# r = generate_user_response(optimum; binary=false)\n",
    "# data_y = [r*ones(jitter)...]\n",
    "# data_x = [[optimum + randn(2)*0.01 for k=1:jitter]...]\n",
    "# optimum = rand(2)\n",
    "# r = generate_user_response(optimum; binary=false)\n",
    "# data_y = [data_y..., r*ones(jitter)...]\n",
    "# data_x = [data_x..., [optimum + randn(2)*0.01 for k=1:jitter]...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_parameters(params, flow_model, data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @code_warntype calculate_parameters(params, flow_model, data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @benchmark calculate_parameters($params, $flow_model, $data_x, $data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_parameters(params, flow_model, data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Profile\n",
    "\n",
    "# @profile calculate_parameters(params, flow_model, data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # type stable\n",
    "# BenchmarkTools.Trial: \n",
    "#   memory estimate:  243.89 MiB\n",
    "#   allocs estimate:  3022996\n",
    "#   --------------\n",
    "#   minimum time:     623.854 ms (4.87% GC)\n",
    "#   median time:      644.346 ms (4.91% GC)\n",
    "#   mean time:        656.192 ms (4.89% GC)\n",
    "#   maximum time:     713.424 ms (4.75% GC)\n",
    "#   --------------\n",
    "#   samples:          8\n",
    "#   evals/sample:     1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initial\n",
    "# BenchmarkTools.Trial: \n",
    "#   memory estimate:  244.15 MiB\n",
    "#   allocs estimate:  3035514\n",
    "#   --------------\n",
    "#   minimum time:     751.122 ms (4.73% GC)\n",
    "#   median time:      825.649 ms (4.95% GC)\n",
    "#   mean time:        849.803 ms (4.95% GC)\n",
    "#   maximum time:     1.027 s (4.25% GC)\n",
    "#   --------------\n",
    "#   samples:          7\n",
    "#   evals/sample:     1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
