{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User preference learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "\n",
    "using ReactiveMP\n",
    "using Rocket\n",
    "using GraphPPL\n",
    "\n",
    "using Optim\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using PyPlot\n",
    "using StatsFuns: normcdf\n",
    "\n",
    "\n",
    "include(\"../src/environment/user.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify flow model\n",
    "flow_model = FlowModel(2,\n",
    "    (\n",
    "        AdditiveCouplingLayer(PlanarFlow()), # defaults to AdditiveCouplingLayer(PlanarFlow(); permute=true)\n",
    "        AdditiveCouplingLayer(PlanarFlow()),\n",
    "        AdditiveCouplingLayer(PlanarFlow()),\n",
    "        AdditiveCouplingLayer(PlanarFlow(); permute=false)\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function flow_classifier(nr_samples::Int64, model::FlowModel, params)\n",
    "    \n",
    "    # initialize variables\n",
    "    x_lat  = randomvar(nr_samples)\n",
    "    y_lat1 = randomvar(nr_samples)\n",
    "    y_lat2 = randomvar(nr_samples)\n",
    "    y      = datavar(Float64, nr_samples)\n",
    "    x      = datavar(Vector{Float64}, nr_samples)\n",
    "\n",
    "    # compile flow model\n",
    "    meta  = FlowMeta(compile(model, params)) # default: FlowMeta(model, Linearization())\n",
    "\n",
    "    # specify observations\n",
    "    for k = 1:nr_samples\n",
    "\n",
    "        # specify latent state\n",
    "        x_lat[k] ~ MvNormalMeanPrecision(x[k], 1e3*diagm(ones(2)))\n",
    "\n",
    "\n",
    "        # specify transformed latent value\n",
    "        y_lat1[k] ~ Flow(x_lat[k]) where { meta = meta }\n",
    "        y_lat2[k] ~ dot(y_lat1[k], [1, 1])\n",
    "\n",
    "        # specify observations\n",
    "        y[k] ~ Probit(y_lat2[k]) # default: where { pipeline = RequireInbound(in = NormalMeanPrecision(0, 1.0)) }\n",
    "\n",
    "    end\n",
    "\n",
    "    # return variables\n",
    "    return x_lat, x, y_lat1, y_lat2, y\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function inference_flow_classifier(data_y::Array{Float64,1}, data_x::Array{Array{Float64,1},1}, model::FlowModel, params)\n",
    "    \n",
    "    # fetch number of samples\n",
    "    nr_samples = length(data_y)\n",
    "\n",
    "    # define model\n",
    "    model, (x_lat, x, y_lat1, y_lat2, y) = flow_classifier(nr_samples, model, params)\n",
    "\n",
    "    # initialize free energy\n",
    "    fe_buffer = nothing\n",
    "    \n",
    "    # subscribe\n",
    "    fe_sub = subscribe!(score(BetheFreeEnergy(), model), (fe) -> fe_buffer = fe)\n",
    "\n",
    "    # update y and x according to observations (i.e. perform inference)\n",
    "    ReactiveMP.update!(y, data_y)\n",
    "    ReactiveMP.update!(x, data_x)\n",
    "\n",
    "    # unsubscribe\n",
    "    unsubscribe!(fe_sub)\n",
    "    \n",
    "    # return the marginal values\n",
    "    return fe_buffer\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculate_parameters (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calculate_parameters(params, model, data_x, data_y)\n",
    "\n",
    "    function f(params)\n",
    "        fe = inference_flow_classifier(data_y, data_x, model, params)\n",
    "        return fe\n",
    "    end\n",
    "\n",
    "    res = optimize(f, params, LBFGS(), Optim.Options(iterations = 500, store_trace = false, show_trace = false), autodiff=:forward)\n",
    "\n",
    "    return Optim.minimizer(res)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repeat_calculate_parameters (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function repeat_calculate_parameters(model, data_x, data_y)\n",
    "    try\n",
    "        return calculate_parameters(randn(nr_params(model)), model, data_x, data_y)\n",
    "    catch\n",
    "        println(\"   ERROR: calculate_parameters() failed\")\n",
    "        return repeat_calculate_parameters(model, data_x, data_y)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference input estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct PointMassFormConstraint2{P}\n",
    "    point :: P   \n",
    "end\n",
    "\n",
    "ReactiveMP.default_form_check_strategy(::PointMassFormConstraint2) = FormConstraintCheckLast()\n",
    "\n",
    "ReactiveMP.is_point_mass_form_constraint(::PointMassFormConstraint2) = true\n",
    "\n",
    "function ReactiveMP.constrain_form(pmconstraint::PointMassFormConstraint2, message::Message) \n",
    "    is_clamped = ReactiveMP.is_clamped(message)\n",
    "    is_initial = ReactiveMP.is_initial(message)\n",
    "    return Message(PointMass(pmconstraint.point), is_clamped, is_initial)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function flow_classifier_input(input, model, params)\n",
    "    \n",
    "    # initialize variables\n",
    "    x_lat  = randomvar()\n",
    "    y_lat1 = randomvar()\n",
    "    y_lat2 = randomvar()\n",
    "    xprior = randomvar() where { form_constraint = PointMassFormConstraint2(input)}\n",
    "    y = datavar(Float64)\n",
    "\n",
    "    # specify model\n",
    "    meta  = FlowMeta(compile(model, params))\n",
    "\n",
    "    # specify prior on weights\n",
    "    xprior ~ MvNormalMeanPrecision([0.5,0.5], 0.1*diagm(ones(2))) where { q = MeanField() }\n",
    "\n",
    "    # specify latent state\n",
    "    x_lat ~ MvNormalMeanPrecision(xprior, 1e3*diagm(ones(2))) where { q = MeanField() }\n",
    "\n",
    "    # specify transformed latent value\n",
    "    y_lat1 ~ Flow(x_lat) where { meta = meta }\n",
    "    y_lat2 ~ dot(y_lat1, [1, 1])\n",
    "\n",
    "    # specify observations\n",
    "    y ~ Probit(y_lat2) # default where { pipeline = RequireInbound(in = NormalMeanPrecision(0, 1.0)) }\n",
    "\n",
    "    # return variables\n",
    "    return x_lat, y_lat1, y_lat2, y\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "function inference_flow_classifier_input(input, model, params)\n",
    "\n",
    "    # define model\n",
    "    model, (x_lat, y_lat1, y_lat2, y) = flow_classifier_input(input, model, params)\n",
    "\n",
    "    # initialize free energy\n",
    "    fe_buffer = nothing\n",
    "    \n",
    "    # subscribe\n",
    "    fe_sub = subscribe!(score(eltype(input), BetheFreeEnergy(), model), (fe) -> fe_buffer = fe)\n",
    "\n",
    "    setmarginal!(x_lat, vague(MvNormalMeanPrecision, 2))\n",
    "    \n",
    "    # update y and x according to observations (i.e. perform inference)\n",
    "    for k = 1:10\n",
    "        ReactiveMP.update!(y, 1.0)\n",
    "    end\n",
    "\n",
    "    # unsubscribe\n",
    "    unsubscribe!(fe_sub)\n",
    "    \n",
    "    # return the marginal values\n",
    "    return fe_buffer\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculate_input (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calculate_input(params, model)\n",
    "\n",
    "    function f_input(input)\n",
    "        fe = inference_flow_classifier_input(input, model, params)\n",
    "        return fe\n",
    "    end\n",
    "\n",
    "    res = optimize(f_input, zeros(2), ones(2), rand(2), Fminbox(LBFGS()), Optim.Options(iterations = 500, store_trace = false, show_trace = false), autodiff=:forward)\n",
    "\n",
    "    return Optim.minimizer(res)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repeat_calculate_input (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function repeat_calculate_input(params, model)\n",
    "    try\n",
    "        return calculate_input(params, model)\n",
    "    catch\n",
    "        println(\"   ERROR: calculate_input() failed\")\n",
    "        return repeat_calculate_input(params, model)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot_figure (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function plot_figure(model, data_x, data_y, it)\n",
    "    classification_map = map((x) -> normcdf(dot([1,1],x)), map((x) -> forward(model, [x...]), collect(Iterators.product(0:0.01:1, 0:0.01:1))))\n",
    "    fig, ax = plt.subplots(ncols = 1)\n",
    "    im = ax.contourf(repeat(0:0.01:1, 1, 101), repeat(0:0.01:1, 1, 101)', classification_map)\n",
    "    ax.scatter(hcat(data_x...)[1,:], hcat(data_x...)[2,:], c=data_y, marker=\"x\")\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(\"gain 1\"), ax.set_ylabel(\"gain 2\")\n",
    "    ax.set_title(string(\"Call \", it));\n",
    "    plt.savefig(string(\"exports/NF_preferences_continuous_\", it, \".eps\"))\n",
    "    plt.savefig(string(\"exports/NF_preferences_continuous_\", it, \".png\"))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User preference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learn_user_preferences (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function learn_user_preferences(model; jitter=1, μ=[0.8, 0.2], a=1, b=1, c=25, d=-0.4)\n",
    "\n",
    "    # set flags\n",
    "    DONE = false\n",
    "    it = 1\n",
    "\n",
    "    # select random data point (initial)\n",
    "    optimum = rand(2)\n",
    "    r = generate_user_response(optimum; μ=μ, a=a, b=b, c=c, d=d, binary=false)\n",
    "    data_y = [r*ones(jitter)...]\n",
    "    data_x = [[optimum + randn(2)*0.01 for k=1:jitter]...]\n",
    "    optimum = rand(2)\n",
    "    r = generate_user_response(optimum; μ=μ, a=a, b=b, c=c, d=d, binary=false)\n",
    "    data_y = [data_y..., r*ones(jitter)...]\n",
    "    data_x = [data_x..., [optimum + randn(2)*0.01 for k=1:jitter]...]\n",
    "\n",
    "    # preference learning loop\n",
    "    while DONE == false && it <= 20\n",
    "\n",
    "        # calculate parameters\n",
    "        params = repeat_calculate_parameters(flow_model, data_x, data_y)\n",
    "        inferred_model = compile(flow_model, params)\n",
    "\n",
    "        # create plot\n",
    "        plot_figure(inferred_model, data_x, data_y, it)\n",
    "\n",
    "        # propose preferences\n",
    "        optimum = repeat_calculate_input(params, flow_model)\n",
    "\n",
    "        # updata data\n",
    "        r = generate_user_response(optimum; μ=μ, a=a, b=b, c=c, d=d, binary=false)\n",
    "        data_y = [data_y..., r*ones(jitter)...]\n",
    "        data_x = [data_x..., [optimum + randn(2)*0.01 for k=1:jitter]...]\n",
    "\n",
    "        # print summary\n",
    "        println(string(\"Iteration \", it, \":\"))\n",
    "        println(string(\"    proposal: \", optimum))\n",
    "        println(string(\"    response: \", r))\n",
    "\n",
    "        # check if done\n",
    "        if r == 1\n",
    "            DONE = true\n",
    "        end\n",
    "\n",
    "        # update iteration number\n",
    "        it += 1\n",
    "\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "    proposal: [0.9618048185390665, 0.953398800217639]\n",
      "    response: 1.6415220122966082e-7\n",
      "Iteration 2:\n",
      "    proposal: [0.08804061051513122, 0.6478455892371975]\n",
      "    response: 3.1256298881088537e-8\n",
      "   ERROR: calculate_parameters() failed\n",
      "   ERROR: calculate_parameters() failed\n",
      "   ERROR: calculate_parameters() failed\n",
      "Iteration 3:\n",
      "    proposal: [0.49675276182456163, 0.5429455435041916]\n",
      "    response: 0.00025697221214256264\n",
      "Iteration 4:\n",
      "    proposal: [0.45799493334307206, 0.9999998409369105]\n",
      "    response: 1.5826385593548454e-8\n",
      "Iteration 5:\n",
      "    proposal: [0.9999999130555673, 0.24980002339523333]\n",
      "    response: 0.08728668588400713\n",
      "Iteration 6:\n",
      "    proposal: [0.9977823414057899, 0.1665349029795411]\n",
      "    response: 0.0981843602748777\n",
      "Iteration 7:\n",
      "    proposal: [0.0007142937990713972, 0.6633020455469304]\n",
      "    response: 4.463997668073824e-9\n",
      "   ERROR: calculate_parameters() failed\n",
      "Iteration 8:\n",
      "    proposal: [0.9999994590596533, 0.18772635777000313]\n",
      "    response: 0.09863889152359374\n",
      "   ERROR: calculate_parameters() failed\n",
      "Iteration 9:\n",
      "    proposal: [0.9999998013844492, 0.13101643973899435]\n",
      "    response: 0.0775915725331643\n",
      "Iteration 10:\n",
      "    proposal: [0.37764747092327755, 0.9997940150694596]\n",
      "    response: 7.043469467305222e-9\n",
      "Iteration 11:\n",
      "    proposal: [0.9999999999999999, 0.7292567234698486]\n",
      "    response: 2.027413829276329e-5\n",
      "Iteration 12:\n",
      "    proposal: [0.9999999999999999, 0.19620035438463534]\n",
      "    response: 0.0993513107310876\n",
      "   ERROR: calculate_parameters() failed\n",
      "Iteration 13:\n",
      "    proposal: [0.9999998460189055, 0.19047923157711072]\n",
      "    response: 0.09895168418823262\n",
      "Iteration 14:\n",
      "    proposal: [0.9999991109321592, 0.20150995903077898]\n",
      "    response: 0.09941715429928473\n",
      "Iteration 15:\n",
      "    proposal: [0.9999998763358035, 0.17337204218440094]\n",
      "    response: 0.0957723738409341\n",
      "Iteration 16:\n",
      "    proposal: [0.9999478611083614, 0.20153388286780555]\n",
      "    response: 0.09952473363370876\n",
      "   ERROR: calculate_parameters() failed\n",
      "   ERROR: calculate_parameters() failed\n",
      "Iteration 17:\n",
      "    proposal: [0.615536157059575, 0.9999884642240522]\n",
      "    response: 5.0170948473803135e-8\n",
      "   ERROR: calculate_parameters() failed\n",
      "Iteration 18:\n",
      "    proposal: [0.6077766659683239, 0.999999568284446]\n",
      "    response: 4.810385940596429e-8\n",
      "Iteration 19:\n",
      "    proposal: [0.5865094886222825, 0.9999896582433824]\n",
      "    response: 4.254920643837976e-8\n",
      "   ERROR: calculate_parameters() failed\n",
      "Iteration 20:\n",
      "    proposal: [0.8638078854720548, 0.6439975962101048]\n",
      "    response: 0.00031924773966295034\n",
      "   ERROR: calculate_parameters() failed\n",
      "Iteration 21:\n",
      "    proposal: [0.7972651045514646, 0.23311224360571114]\n",
      "    response: 0.8479502031353989\n",
      "   ERROR: calculate_parameters() failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22:\n",
      "    proposal: [0.592543233476699, 0.001102606992175126]\n",
      "    response: 0.013938442655543849\n",
      "Iteration 23:\n",
      "    proposal: [0.9999997986940665, 0.9999697764997129]\n",
      "    response: 4.608552870880231e-8\n",
      "Iteration 24:\n",
      "    proposal: [0.7256612731036888, 0.0006117650750028237]\n",
      "    response: 0.07554131603981132\n",
      "Iteration 25:\n",
      "    proposal: [0.5487524419572124, 0.6770836749827464]\n",
      "    response: 3.7887046274469396e-5\n",
      "Iteration 26:\n",
      "    proposal: [0.6717388447165289, 0.7603978537847146]\n",
      "    response: 1.636682132936125e-5\n",
      "Iteration 27:\n",
      "    proposal: [0.0022284728940344944, 0.9313996027479462]\n",
      "    response: 1.0748392398356152e-10\n",
      "   ERROR: calculate_parameters() failed\n",
      "   ERROR: calculate_parameters() failed\n",
      "Iteration 28:\n",
      "    proposal: [0.3997324891636257, 0.9148384202887113]\n",
      "    response: 5.222641869502264e-8\n",
      "Iteration 29:\n",
      "    proposal: [0.9999999806537833, 0.9999999464243668]\n",
      "    response: 4.605376879744273e-8\n",
      "   ERROR: calculate_parameters() failed\n"
     ]
    }
   ],
   "source": [
    "learn_user_preferences(flow_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ", ax = plt.subplots(ncols=1)\n",
    "classification_map = map((x) -> generate_user_response([x...]; μ=μ, a=a, b=b, c=c, d=d, binary=false), collect(Iterators.product(0:0.01:1, 0:0.01:1))))\n",
    "im = ax.contourf(repeat(0:0.01:1, 1, 101), repeat(0:0.01:1, 1, 101)', classification_map)\n",
    "plt.colorbar(im, ax=ax)\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"gain 1\"), ax.set_ylabel(\"gain 2\")\n",
    "ax.set_title(\"Actual user response\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
